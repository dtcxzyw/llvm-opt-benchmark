target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%"struct.eastl::internal::memory_order_read_depends_s" = type { i8 }
%struct.ReadDependsStruct = type { i32, i32 }
%"struct.eastl::internal::memory_order_release_s" = type { i8 }
%"struct.eastl::internal::memory_order_relaxed_s" = type { i8 }
%"struct.eastl::internal::memory_order_seq_cst_s" = type { i8 }
%"struct.eastl::internal::memory_order_acquire_s" = type { i8 }
%"struct.eastl::internal::memory_order_acq_rel_s" = type { i8 }
%struct.UserType128 = type { i32, i32, i32, i32 }
%struct.ReadDependsIntrusive = type { i32, i32, ptr, i32, i32 }
%"struct.eastl::atomic.5" = type { %"struct.eastl::internal::atomic_integral_width" }
%"struct.eastl::internal::atomic_integral_width" = type { %"struct.eastl::internal::atomic_integral_base" }
%"struct.eastl::internal::atomic_integral_base" = type { %"struct.eastl::internal::atomic_base_width.6" }
%"struct.eastl::internal::atomic_base_width.6" = type { %"struct.eastl::internal::atomic_size_aligned.7" }
%"struct.eastl::internal::atomic_size_aligned.7" = type { i32 }
%"struct.eastl::atomic.8" = type { %"struct.eastl::internal::atomic_integral_width.9" }
%"struct.eastl::internal::atomic_integral_width.9" = type { %"struct.eastl::internal::atomic_integral_base.10" }
%"struct.eastl::internal::atomic_integral_base.10" = type { %"struct.eastl::internal::atomic_base_width.11" }
%"struct.eastl::internal::atomic_base_width.11" = type { %"struct.eastl::internal::atomic_size_aligned.12" }
%"struct.eastl::internal::atomic_size_aligned.12" = type { i64 }
%"struct.eastl::atomic.13" = type { %"struct.eastl::internal::atomic_base_width.14" }
%"struct.eastl::internal::atomic_base_width.14" = type { %"struct.eastl::internal::atomic_size_aligned.15" }
%"struct.eastl::internal::atomic_size_aligned.15" = type { %struct.UserType128 }
%"struct.eastl::atomic.16" = type { %"struct.eastl::internal::atomic_integral_width.17" }
%"struct.eastl::internal::atomic_integral_width.17" = type { %"struct.eastl::internal::atomic_integral_base.18" }
%"struct.eastl::internal::atomic_integral_base.18" = type { %"struct.eastl::internal::atomic_base_width.19" }
%"struct.eastl::internal::atomic_base_width.19" = type { %"struct.eastl::internal::atomic_size_aligned.20" }
%"struct.eastl::internal::atomic_size_aligned.20" = type { i128 }
%"struct.eastl::atomic.21" = type { %"struct.eastl::internal::atomic_pointer_width.22" }
%"struct.eastl::internal::atomic_pointer_width.22" = type { %"struct.eastl::internal::atomic_pointer_base.23" }
%"struct.eastl::internal::atomic_pointer_base.23" = type { %"struct.eastl::internal::atomic_base_width.24" }
%"struct.eastl::internal::atomic_base_width.24" = type { %"struct.eastl::internal::atomic_size_aligned.25" }
%"struct.eastl::internal::atomic_size_aligned.25" = type { ptr }
%"struct.eastl::aligned_storage<8>::type" = type { [8 x i8] }
%"struct.eastl::aligned_storage<16, 16>::type" = type { [16 x i8] }
%"struct.eastl::aligned_storage<16, 4>::type" = type { [16 x i8] }
%"struct.eastl::internal::atomic_size_aligned.4" = type { ptr }
%"struct.eastl::internal::atomic_size_aligned" = type { ptr }

$_ZN5eastl8internal20atomic_pointer_widthIP17ReadDependsStructLj8EE4loadENS0_27memory_order_read_depends_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIP17ReadDependsStructLj8EE5storeES3_NS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIPP20ReadDependsIntrusiveLj8EE5storeES4_NS0_22memory_order_release_sE = comdat any

$_ZN5eastl6atomicIjvEC2Ev = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EEC2Ev = comdat any

$_ZN5eastl8internal20atomic_integral_baseIjLj4EEC2Ev = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EEC2Ev = comdat any

$_ZN5eastl8internal19atomic_size_alignedIjEC2Ev = comdat any

$_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv = comdat any

$_ZN5eastl9addressofIjEEPT_RS1_ = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEj = comdat any

$_ZN5eastl6atomicImvEC2Ev = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE5storeEmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EEC2Ev = comdat any

$_ZN5eastl8internal20atomic_integral_baseImLj8EEC2Ev = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EEC2Ev = comdat any

$_ZN5eastl8internal19atomic_size_alignedImEC2Ev = comdat any

$_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv = comdat any

$_ZN5eastl9addressofImEEPT_RS1_ = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE5storeEmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE5storeEmNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE5storeEm = comdat any

$_ZN5eastl6atomicI11UserType128vEC2Ev = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_NS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EEC2Ev = comdat any

$_ZN5eastl8internal19atomic_size_alignedI11UserType128EC2Ev = comdat any

$_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv = comdat any

$_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_ = comdat any

$_ZN5eastl9addressofIK11UserType128EEPT_RS3_ = comdat any

$_ZN5eastl9addressofI11UserType128EEPT_RS2_ = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_NS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_NS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_ = comdat any

$_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadENS0_22memory_order_relaxed_sE = comdat any

$_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadENS0_22memory_order_acquire_sE = comdat any

$_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadENS0_22memory_order_seq_cst_sE = comdat any

$_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadEv = comdat any

$_ZNK5eastl8internal17atomic_base_widthImLj8EE4loadENS0_22memory_order_relaxed_sE = comdat any

$_ZNK5eastl8internal17atomic_base_widthImLj8EE4loadENS0_22memory_order_acquire_sE = comdat any

$_ZNK5eastl8internal17atomic_base_widthImLj8EE4loadENS0_22memory_order_seq_cst_sE = comdat any

$_ZNK5eastl8internal17atomic_base_widthImLj8EE4loadEv = comdat any

$_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl9addressofINS_15aligned_storageILm16ELm4EE4typeEEEPT_RS4_ = comdat any

$_ZN5eastl9addressofIKoEEPT_RS2_ = comdat any

$_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadENS0_22memory_order_acquire_sE = comdat any

$_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadENS0_22memory_order_seq_cst_sE = comdat any

$_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadEv = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEj = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEm = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_NS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_NS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_NS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_NS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_ = comdat any

$_ZNK5eastl6atomicIjvEcvjEv = comdat any

$_ZNK5eastl6atomicImvEcvmEv = comdat any

$_ZNK5eastl6atomicI11UserType128vEcvS1_Ev = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EEaSEj = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EEaSEm = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EEaSES2_ = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_relaxed_sES4_ = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acquire_sES4_ = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_release_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_seq_cst_sES4_ = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjj = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_relaxed_sES4_ = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acquire_sES4_ = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_release_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_seq_cst_sES4_ = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmm = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_relaxed_sES5_ = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acquire_sES5_ = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_release_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_seq_cst_sES5_ = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_ = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_relaxed_sES4_ = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acquire_sES4_ = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_release_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_seq_cst_sES4_ = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjj = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_relaxed_sES4_ = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acquire_sES4_ = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_release_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_seq_cst_sES4_ = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmm = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_relaxed_sES5_ = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acquire_sES5_ = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_release_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_seq_cst_sES5_ = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_ = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEm = comdat any

$_ZN5eastl6atomicIovEC2Ev = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EEC2Ev = comdat any

$_ZN5eastl8internal20atomic_integral_baseIoLj16EEC2Ev = comdat any

$_ZN5eastl8internal17atomic_base_widthIoLj16EEC2Ev = comdat any

$_ZN5eastl8internal19atomic_size_alignedIoEC2Ev = comdat any

$_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv = comdat any

$_ZN5eastl9addressofIoEEPT_RS1_ = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEmNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEmNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_relaxed_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_acquire_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_release_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_acq_rel_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_seq_cst_sE = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EEppEi = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EEppEi = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EEppEi = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EEppEv = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EEppEv = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EEppEv = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EEmmEi = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EEmmEi = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EEmmEi = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EEmmEv = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EEmmEv = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EEmmEv = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EEpLEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EEpLEm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EEpLEo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EEmIEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EEmIEm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EEmIEo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EEaNEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EEaNEm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EEaNEo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EEoREj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EEoREm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EEoREo = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EEeOEj = comdat any

$_ZN5eastl8internal21atomic_integral_widthImLj8EEeOEm = comdat any

$_ZN5eastl8internal21atomic_integral_widthIoLj16EEeOEo = comdat any

$_ZN5eastl6atomicIPvvEC2Ev = comdat any

$_ZN5eastl8internal20atomic_pointer_widthIPvLj8EE4loadENS0_27memory_order_read_depends_sE = comdat any

$_ZN5eastl8internal20atomic_pointer_widthIPvLj8EEC2Ev = comdat any

$_ZN5eastl8internal19atomic_pointer_baseIPvLj8EEC2Ev = comdat any

$_ZN5eastl8internal17atomic_base_widthIPvLj8EEC2Ev = comdat any

$_ZN5eastl8internal19atomic_size_alignedIPvEC2Ev = comdat any

$_ZNK5eastl8internal19atomic_size_alignedIPvE16GetAtomicAddressEv = comdat any

$_ZN5eastl9addressofIPvEEPT_RS2_ = comdat any

$_ZN5eastl8internal20atomic_pointer_widthIPP20ReadDependsIntrusiveLj8EE4loadENS0_27memory_order_read_depends_sE = comdat any

$_ZNK5eastl8internal19atomic_size_alignedIPP20ReadDependsIntrusiveE16GetAtomicAddressEv = comdat any

$_ZN5eastl9addressofIPP20ReadDependsIntrusiveEEPT_RS4_ = comdat any

$_ZN5eastl6atomicIjvEC2Ej = comdat any

$_ZN5eastl8internal21atomic_integral_widthIjLj4EEC2Ej = comdat any

$_ZN5eastl8internal20atomic_integral_baseIjLj4EEC2Ej = comdat any

$_ZN5eastl8internal17atomic_base_widthIjLj4EEC2Ej = comdat any

$_ZN5eastl8internal19atomic_size_alignedIjEC2Ej = comdat any

$_ZN5eastl6atomicI11UserType128vEC2ES1_ = comdat any

$_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EEC2ES2_ = comdat any

$_ZN5eastl8internal19atomic_size_alignedI11UserType128EC2ES2_ = comdat any

$_ZNK5eastl8internal19atomic_size_alignedIP17ReadDependsStructE16GetAtomicAddressEv = comdat any

$_ZN5eastl9addressofIP17ReadDependsStructEEPT_RS3_ = comdat any

$_ZN5eastl9addressofINS_15aligned_storageILm8ELm8EE4typeEEEPT_RS4_ = comdat any

$_ZN5eastl9addressofIKP17ReadDependsStructEEPT_RS4_ = comdat any

$_ZN5eastl9addressofIKPP20ReadDependsIntrusiveEEPT_RS5_ = comdat any

@gAtomicPtr = dso_local global { ptr } zeroinitializer, align 8
@_ZN5eastlL25memory_order_read_dependsE = internal constant %"struct.eastl::internal::memory_order_read_depends_s" undef, align 1
@gListHead = dso_local global { ptr } zeroinitializer, align 8
@__const._Z13TestAtomicAsmv.rds = private unnamed_addr constant %struct.ReadDependsStruct { i32 3, i32 2 }, align 4
@_ZN5eastlL20memory_order_releaseE = internal constant %"struct.eastl::internal::memory_order_release_s" undef, align 1
@_ZN5eastlL20memory_order_relaxedE = internal constant %"struct.eastl::internal::memory_order_relaxed_s" undef, align 1
@_ZN5eastlL20memory_order_seq_cstE = internal constant %"struct.eastl::internal::memory_order_seq_cst_s" undef, align 1
@_ZN5eastlL20memory_order_acquireE = internal constant %"struct.eastl::internal::memory_order_acquire_s" undef, align 1
@_ZN5eastlL20memory_order_acq_relE = internal constant %"struct.eastl::internal::memory_order_acq_rel_s" undef, align 1
@__const._ZL33TestCompilerBarrierDataDependencyv.t = private unnamed_addr constant %struct.UserType128 { i32 4, i32 5, i32 7, i32 8 }, align 4

; Function Attrs: mustprogress nounwind uwtable
define dso_local noundef i32 @_Z27TestAtomicReadDependsStructv() #0 {
entry:
  %p = alloca ptr, align 8
  %a = alloca i32, align 4
  %b = alloca i32, align 4
  %call = call noundef ptr @_ZN5eastl8internal20atomic_pointer_widthIP17ReadDependsStructLj8EE4loadENS0_27memory_order_read_depends_sE(ptr noundef nonnull align 8 dereferenceable(8) @gAtomicPtr) #4
  store ptr %call, ptr %p, align 8
  %0 = load ptr, ptr %p, align 8
  %a1 = getelementptr inbounds %struct.ReadDependsStruct, ptr %0, i32 0, i32 0
  %1 = load i32, ptr %a1, align 4
  store i32 %1, ptr %a, align 4
  %2 = load ptr, ptr %p, align 8
  %b2 = getelementptr inbounds %struct.ReadDependsStruct, ptr %2, i32 0, i32 1
  %3 = load i32, ptr %b2, align 4
  store i32 %3, ptr %b, align 4
  %4 = load i32, ptr %a, align 4
  %5 = load i32, ptr %b, align 4
  %add = add nsw i32 %4, %5
  ret i32 %add
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl8internal20atomic_pointer_widthIP17ReadDependsStructLj8EE4loadENS0_27memory_order_read_depends_sE(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %retPointer = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIP17ReadDependsStructE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call, ptr %ptr.addr.i, align 8
  %0 = load ptr, ptr %ptr.addr.i, align 8
  %1 = load volatile ptr, ptr %0, align 8
  store ptr %1, ptr %retPointer, align 8
  %2 = load ptr, ptr %retPointer, align 8
  ret ptr %2
}

; Function Attrs: mustprogress uwtable
define dso_local noundef i32 @_Z13TestAtomicAsmv() #1 {
entry:
  %val.addr.i5 = alloca ptr, align 8
  %val.addr.i = alloca ptr, align 8
  %nErrorCount = alloca i32, align 4
  %rds = alloca %struct.ReadDependsStruct, align 4
  %ret = alloca i32, align 4
  %rdi = alloca %struct.ReadDependsIntrusive, align 8
  %ret3 = alloca i32, align 4
  store i32 0, ptr %nErrorCount, align 4
  call void @_ZL24TestAtomicU32StoreOrdersv()
  call void @_ZL24TestAtomicU64StoreOrdersv()
  call void @_ZL24TestAtomic128StoreOrdersv()
  call void @_ZL23TestAtomicU32LoadOrdersv()
  call void @_ZL23TestAtomicU64LoadOrdersv()
  call void @_ZL23TestAtomic128LoadOrdersv()
  call void @_ZL27TestAtomicU32ExchangeOrdersv()
  call void @_ZL27TestAtomicU64ExchangeOrdersv()
  call void @_ZL27TestAtomic128ExchangeOrdersv()
  call void @_ZL22TestAtomicU32OperatorTv()
  call void @_ZL22TestAtomicU64OperatorTv()
  call void @_ZL22TestAtomic128OperatorTv()
  call void @_ZL26TestAtomicU32OperatorEqualv()
  call void @_ZL26TestAtomicU64OperatorEqualv()
  call void @_ZL26TestAtomic128OperatorEqualv()
  call void @_ZL38TestAtomicU32CompareExchangeWeakOrdersv()
  call void @_ZL38TestAtomicU64CompareExchangeWeakOrdersv()
  call void @_ZL38TestAtomic128CompareExchangeWeakOrdersv()
  call void @_ZL40TestAtomicU32CompareExchangeStrongOrdersv()
  call void @_ZL40TestAtomicU64CompareExchangeStrongOrdersv()
  call void @_ZL40TestAtomic128CompareExchangeStrongOrdersv()
  call void @_ZL27TestAtomicU32FetchAddOrdersv()
  call void @_ZL27TestAtomicU64FetchAddOrdersv()
  call void @_ZL27TestAtomic128FetchAddOrdersv()
  call void @_ZL27TestAtomicU32AddFetchOrdersv()
  call void @_ZL27TestAtomicU64AddFetchOrdersv()
  call void @_ZL27TestAtomic128AddFetchOrdersv()
  call void @_ZL27TestAtomicU32FetchSubOrdersv()
  call void @_ZL27TestAtomicU64FetchSubOrdersv()
  call void @_ZL27TestAtomic128FetchSubOrdersv()
  call void @_ZL27TestAtomicU32SubFetchOrdersv()
  call void @_ZL27TestAtomicU64SubFetchOrdersv()
  call void @_ZL27TestAtomic128SubFetchOrdersv()
  call void @_ZL27TestAtomicU32FetchAndOrdersv()
  call void @_ZL27TestAtomicU64FetchAndOrdersv()
  call void @_ZL27TestAtomic128FetchAndOrdersv()
  call void @_ZL27TestAtomicU32AndFetchOrdersv()
  call void @_ZL27TestAtomicU64AndFetchOrdersv()
  call void @_ZL27TestAtomic128AndFetchOrdersv()
  call void @_ZL26TestAtomicU32FetchOrOrdersv()
  call void @_ZL26TestAtomicU64FetchOrOrdersv()
  call void @_ZL26TestAtomic128FetchOrOrdersv()
  call void @_ZL26TestAtomicU32OrFetchOrdersv()
  call void @_ZL26TestAtomicU64OrFetchOrdersv()
  call void @_ZL26TestAtomic128OrFetchOrdersv()
  call void @_ZL27TestAtomicU32FetchXorOrdersv()
  call void @_ZL27TestAtomicU64FetchXorOrdersv()
  call void @_ZL27TestAtomic128FetchXorOrdersv()
  call void @_ZL27TestAtomicU32XorFetchOrdersv()
  call void @_ZL27TestAtomicU64XorFetchOrdersv()
  call void @_ZL27TestAtomic128XorFetchOrdersv()
  call void @_ZL29TestAtomicU32OperatorPlusPlusv()
  call void @_ZL29TestAtomicU64OperatorPlusPlusv()
  call void @_ZL29TestAtomic128OperatorPlusPlusv()
  call void @_ZL29TestAtomicU32PlusPlusOperatorv()
  call void @_ZL29TestAtomicU64PlusPlusOperatorv()
  call void @_ZL29TestAtomic128PlusPlusOperatorv()
  call void @_ZL31TestAtomicU32OperatorMinusMinusv()
  call void @_ZL31TestAtomicU64OperatorMinusMinusv()
  call void @_ZL31TestAtomic128OperatorMinusMinusv()
  call void @_ZL31TestAtomicU32MinusMinusOperatorv()
  call void @_ZL31TestAtomicU64MinusMinusOperatorv()
  call void @_ZL31TestAtomic128MinusMinusOperatorv()
  call void @_ZL35TestAtomicU32OperatorPlusAssignmentv()
  call void @_ZL35TestAtomicU64OperatorPlusAssignmentv()
  call void @_ZL35TestAtomic128OperatorPlusAssignmentv()
  call void @_ZL36TestAtomicU32OperatorMinusAssignmentv()
  call void @_ZL36TestAtomicU64OperatorMinusAssignmentv()
  call void @_ZL36TestAtomic128OperatorMinusAssignmentv()
  call void @_ZL34TestAtomicU32OperatorAndAssignmentv()
  call void @_ZL34TestAtomicU64OperatorAndAssignmentv()
  call void @_ZL34TestAtomic128OperatorAndAssignmentv()
  call void @_ZL33TestAtomicU32OperatorOrAssignmentv()
  call void @_ZL33TestAtomicU64OperatorOrAssignmentv()
  call void @_ZL33TestAtomic128OperatorOrAssignmentv()
  call void @_ZL34TestAtomicU32OperatorXorAssignmentv()
  call void @_ZL34TestAtomicU64OperatorXorAssignmentv()
  call void @_ZL34TestAtomic128OperatorXorAssignmentv()
  call void @_ZL28TestAtomicSignalFenceRelaxedv()
  call void @_ZL28TestAtomicSignalFenceAcquirev()
  call void @_ZL28TestAtomicSignalFenceReleasev()
  call void @_ZL27TestAtomicSignalFenceAcqRelv()
  call void @_ZL27TestAtomicSignalFenceSeqCstv()
  call void @_ZL28TestAtomicThreadFenceRelaxedv()
  call void @_ZL28TestAtomicThreadFenceAcquirev()
  call void @_ZL28TestAtomicThreadFenceReleasev()
  call void @_ZL27TestAtomicThreadFenceAcqRelv()
  call void @_ZL27TestAtomicThreadFenceSeqCstv()
  call void @_ZL28TestAtomicPointerReadDependsv()
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %rds, ptr align 4 @__const._Z13TestAtomicAsmv.rds, i64 8, i1 false)
  call void @_ZN5eastl8internal17atomic_base_widthIP17ReadDependsStructLj8EE5storeES3_NS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) @gAtomicPtr, ptr noundef %rds) #4
  %call = call noundef i32 @_Z27TestAtomicReadDependsStructv()
  store i32 %call, ptr %ret, align 4
  store ptr %ret, ptr %val.addr.i5, align 8
  %0 = load ptr, ptr %val.addr.i5, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  %a = getelementptr inbounds %struct.ReadDependsIntrusive, ptr %rdi, i32 0, i32 0
  store i32 3, ptr %a, align 8
  %b = getelementptr inbounds %struct.ReadDependsIntrusive, ptr %rdi, i32 0, i32 1
  store i32 2, ptr %b, align 4
  %next = getelementptr inbounds %struct.ReadDependsIntrusive, ptr %rdi, i32 0, i32 2
  store ptr %rdi, ptr %next, align 8
  %c = getelementptr inbounds %struct.ReadDependsIntrusive, ptr %rdi, i32 0, i32 3
  store i32 1, ptr %c, align 8
  %d = getelementptr inbounds %struct.ReadDependsIntrusive, ptr %rdi, i32 0, i32 4
  store i32 0, ptr %d, align 4
  %next1 = getelementptr inbounds %struct.ReadDependsIntrusive, ptr %rdi, i32 0, i32 2
  call void @_ZN5eastl8internal17atomic_base_widthIPP20ReadDependsIntrusiveLj8EE5storeES4_NS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) @gListHead, ptr noundef %next1) #4
  %call4 = call noundef i32 @_ZL30TestAtomicReadDependsIntrusivev()
  store i32 %call4, ptr %ret3, align 4
  store ptr %ret3, ptr %val.addr.i, align 8
  %1 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %1) #4, !srcloc !5
  call void @_ZL33TestCompilerBarrierDataDependencyv()
  call void @_ZL38TestAtomic32LoadStoreSameAddressSeqCstv()
  call void @_ZL39TestAtomic128LoadStoreSameAddressSeqCstv()
  %2 = load i32, ptr %nErrorCount, align 4
  ret i32 %2
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL24TestAtomicU32StoreOrdersv() #1 {
entry:
  call void @_ZL25TestAtomicU32StoreRelaxedv()
  call void @_ZL25TestAtomicU32StoreReleasev()
  call void @_ZL24TestAtomicU32StoreSeqCstv()
  call void @_ZL18TestAtomicU32Storev()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL24TestAtomicU64StoreOrdersv() #1 {
entry:
  call void @_ZL25TestAtomicU64StoreRelaxedv()
  call void @_ZL25TestAtomicU64StoreReleasev()
  call void @_ZL24TestAtomicU64StoreSeqCstv()
  call void @_ZL18TestAtomicU64Storev()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL24TestAtomic128StoreOrdersv() #1 {
entry:
  call void @_ZL25TestAtomic128StoreRelaxedv()
  call void @_ZL25TestAtomic128StoreReleasev()
  call void @_ZL24TestAtomic128StoreSeqCstv()
  call void @_ZL18TestAtomic128Storev()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL23TestAtomicU32LoadOrdersv() #1 {
entry:
  call void @_ZL24TestAtomicU32LoadRelaxedv()
  call void @_ZL24TestAtomicU32LoadAcquirev()
  call void @_ZL23TestAtomicU32LoadSeqCstv()
  call void @_ZL17TestAtomicU32Loadv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL23TestAtomicU64LoadOrdersv() #1 {
entry:
  call void @_ZL24TestAtomicU64LoadRelaxedv()
  call void @_ZL24TestAtomicU64LoadAcquirev()
  call void @_ZL23TestAtomicU64LoadSeqCstv()
  call void @_ZL17TestAtomicU64Loadv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL23TestAtomic128LoadOrdersv() #1 {
entry:
  call void @_ZL24TestAtomic128LoadRelaxedv()
  call void @_ZL24TestAtomic128LoadAcquirev()
  call void @_ZL23TestAtomic128LoadSeqCstv()
  call void @_ZL17TestAtomic128Loadv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU32ExchangeOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU32ExchangeRelaxedv()
  call void @_ZL28TestAtomicU32ExchangeAcquirev()
  call void @_ZL28TestAtomicU32ExchangeReleasev()
  call void @_ZL27TestAtomicU32ExchangeAcqRelv()
  call void @_ZL27TestAtomicU32ExchangeSeqCstv()
  call void @_ZL21TestAtomicU32Exchangev()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU64ExchangeOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU64ExchangeRelaxedv()
  call void @_ZL28TestAtomicU64ExchangeAcquirev()
  call void @_ZL28TestAtomicU64ExchangeReleasev()
  call void @_ZL27TestAtomicU64ExchangeAcqRelv()
  call void @_ZL27TestAtomicU64ExchangeSeqCstv()
  call void @_ZL21TestAtomicU64Exchangev()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomic128ExchangeOrdersv() #1 {
entry:
  call void @_ZL28TestAtomic128ExchangeRelaxedv()
  call void @_ZL28TestAtomic128ExchangeAcquirev()
  call void @_ZL28TestAtomic128ExchangeReleasev()
  call void @_ZL27TestAtomic128ExchangeAcqRelv()
  call void @_ZL27TestAtomic128ExchangeSeqCstv()
  call void @_ZL21TestAtomic128Exchangev()
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL22TestAtomicU32OperatorTv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %load = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZNK5eastl6atomicIjvEcvjEv(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 %call, ptr %load, align 4
  store ptr %load, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL22TestAtomicU64OperatorTv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %load = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZNK5eastl6atomicImvEcvmEv(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 %call, ptr %load, align 8
  store ptr %load, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL22TestAtomic128OperatorTv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %load = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %call = call { i64, i64 } @_ZNK5eastl6atomicI11UserType128vEcvS1_Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %0 = getelementptr inbounds { i64, i64 }, ptr %load, i32 0, i32 0
  %1 = extractvalue { i64, i64 } %call, 0
  store i64 %1, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %load, i32 0, i32 1
  %3 = extractvalue { i64, i64 } %call, 1
  store i64 %3, ptr %2, align 4
  store ptr %load, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomicU32OperatorEqualv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EEaSEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomicU64OperatorEqualv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EEaSEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomic128OperatorEqualv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %agg.tmp = alloca %struct.UserType128, align 4
  %coerce = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call { i64, i64 } @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EEaSES2_(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %1, i64 %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 4
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 4
  store ptr %atomic, ptr %val.addr.i, align 8
  %8 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %8) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL38TestAtomicU32CompareExchangeWeakOrdersv() #1 {
entry:
  call void @_ZL46TestAtomicU32CompareExchangeWeakRelaxedRelaxedv()
  call void @_ZL46TestAtomicU32CompareExchangeWeakAcquireRelaxedv()
  call void @_ZL46TestAtomicU32CompareExchangeWeakAcquireAcquirev()
  call void @_ZL46TestAtomicU32CompareExchangeWeakReleaseRelaxedv()
  call void @_ZL45TestAtomicU32CompareExchangeWeakAcqRelRelaxedv()
  call void @_ZL45TestAtomicU32CompareExchangeWeakAcqRelAcquirev()
  call void @_ZL45TestAtomicU32CompareExchangeWeakSeqCstRelaxedv()
  call void @_ZL45TestAtomicU32CompareExchangeWeakSeqCstAcquirev()
  call void @_ZL44TestAtomicU32CompareExchangeWeakSeqCstSeqCstv()
  call void @_ZL39TestAtomicU32CompareExchangeWeakRelaxedv()
  call void @_ZL39TestAtomicU32CompareExchangeWeakAcquirev()
  call void @_ZL39TestAtomicU32CompareExchangeWeakReleasev()
  call void @_ZL38TestAtomicU32CompareExchangeWeakAcqRelv()
  call void @_ZL38TestAtomicU32CompareExchangeWeakSeqCstv()
  call void @_ZL32TestAtomicU32CompareExchangeWeakv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL38TestAtomicU64CompareExchangeWeakOrdersv() #1 {
entry:
  call void @_ZL46TestAtomicU64CompareExchangeWeakRelaxedRelaxedv()
  call void @_ZL46TestAtomicU64CompareExchangeWeakAcquireRelaxedv()
  call void @_ZL46TestAtomicU64CompareExchangeWeakAcquireAcquirev()
  call void @_ZL46TestAtomicU64CompareExchangeWeakReleaseRelaxedv()
  call void @_ZL45TestAtomicU64CompareExchangeWeakAcqRelRelaxedv()
  call void @_ZL45TestAtomicU64CompareExchangeWeakAcqRelAcquirev()
  call void @_ZL45TestAtomicU64CompareExchangeWeakSeqCstRelaxedv()
  call void @_ZL45TestAtomicU64CompareExchangeWeakSeqCstAcquirev()
  call void @_ZL44TestAtomicU64CompareExchangeWeakSeqCstSeqCstv()
  call void @_ZL39TestAtomicU64CompareExchangeWeakRelaxedv()
  call void @_ZL39TestAtomicU64CompareExchangeWeakAcquirev()
  call void @_ZL39TestAtomicU64CompareExchangeWeakReleasev()
  call void @_ZL38TestAtomicU64CompareExchangeWeakAcqRelv()
  call void @_ZL38TestAtomicU64CompareExchangeWeakSeqCstv()
  call void @_ZL32TestAtomicU64CompareExchangeWeakv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL38TestAtomic128CompareExchangeWeakOrdersv() #1 {
entry:
  call void @_ZL46TestAtomic128CompareExchangeWeakRelaxedRelaxedv()
  call void @_ZL46TestAtomic128CompareExchangeWeakAcquireRelaxedv()
  call void @_ZL46TestAtomic128CompareExchangeWeakAcquireAcquirev()
  call void @_ZL46TestAtomic128CompareExchangeWeakReleaseRelaxedv()
  call void @_ZL45TestAtomic128CompareExchangeWeakAcqRelRelaxedv()
  call void @_ZL45TestAtomic128CompareExchangeWeakAcqRelAcquirev()
  call void @_ZL45TestAtomic128CompareExchangeWeakSeqCstRelaxedv()
  call void @_ZL45TestAtomic128CompareExchangeWeakSeqCstAcquirev()
  call void @_ZL44TestAtomic128CompareExchangeWeakSeqCstSeqCstv()
  call void @_ZL39TestAtomic128CompareExchangeWeakRelaxedv()
  call void @_ZL39TestAtomic128CompareExchangeWeakAcquirev()
  call void @_ZL39TestAtomic128CompareExchangeWeakReleasev()
  call void @_ZL38TestAtomic128CompareExchangeWeakAcqRelv()
  call void @_ZL38TestAtomic128CompareExchangeWeakSeqCstv()
  call void @_ZL32TestAtomic128CompareExchangeWeakv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL40TestAtomicU32CompareExchangeStrongOrdersv() #1 {
entry:
  call void @_ZL48TestAtomicU32CompareExchangeStrongRelaxedRelaxedv()
  call void @_ZL48TestAtomicU32CompareExchangeStrongAcquireRelaxedv()
  call void @_ZL48TestAtomicU32CompareExchangeStrongAcquireAcquirev()
  call void @_ZL48TestAtomicU32CompareExchangeStrongReleaseRelaxedv()
  call void @_ZL47TestAtomicU32CompareExchangeStrongAcqRelRelaxedv()
  call void @_ZL47TestAtomicU32CompareExchangeStrongAcqRelAcquirev()
  call void @_ZL47TestAtomicU32CompareExchangeStrongSeqCstRelaxedv()
  call void @_ZL47TestAtomicU32CompareExchangeStrongSeqCstAcquirev()
  call void @_ZL46TestAtomicU32CompareExchangeStrongSeqCstSeqCstv()
  call void @_ZL41TestAtomicU32CompareExchangeStrongRelaxedv()
  call void @_ZL41TestAtomicU32CompareExchangeStrongAcquirev()
  call void @_ZL41TestAtomicU32CompareExchangeStrongReleasev()
  call void @_ZL40TestAtomicU32CompareExchangeStrongAcqRelv()
  call void @_ZL40TestAtomicU32CompareExchangeStrongSeqCstv()
  call void @_ZL34TestAtomicU32CompareExchangeStrongv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL40TestAtomicU64CompareExchangeStrongOrdersv() #1 {
entry:
  call void @_ZL48TestAtomicU64CompareExchangeStrongRelaxedRelaxedv()
  call void @_ZL48TestAtomicU64CompareExchangeStrongAcquireRelaxedv()
  call void @_ZL48TestAtomicU64CompareExchangeStrongAcquireAcquirev()
  call void @_ZL48TestAtomicU64CompareExchangeStrongReleaseRelaxedv()
  call void @_ZL47TestAtomicU64CompareExchangeStrongAcqRelRelaxedv()
  call void @_ZL47TestAtomicU64CompareExchangeStrongAcqRelAcquirev()
  call void @_ZL47TestAtomicU64CompareExchangeStrongSeqCstRelaxedv()
  call void @_ZL47TestAtomicU64CompareExchangeStrongSeqCstAcquirev()
  call void @_ZL46TestAtomicU64CompareExchangeStrongSeqCstSeqCstv()
  call void @_ZL41TestAtomicU64CompareExchangeStrongRelaxedv()
  call void @_ZL41TestAtomicU64CompareExchangeStrongAcquirev()
  call void @_ZL41TestAtomicU64CompareExchangeStrongReleasev()
  call void @_ZL40TestAtomicU64CompareExchangeStrongAcqRelv()
  call void @_ZL40TestAtomicU64CompareExchangeStrongSeqCstv()
  call void @_ZL34TestAtomicU64CompareExchangeStrongv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL40TestAtomic128CompareExchangeStrongOrdersv() #1 {
entry:
  call void @_ZL48TestAtomic128CompareExchangeStrongRelaxedRelaxedv()
  call void @_ZL48TestAtomic128CompareExchangeStrongAcquireRelaxedv()
  call void @_ZL48TestAtomic128CompareExchangeStrongAcquireAcquirev()
  call void @_ZL48TestAtomic128CompareExchangeStrongReleaseRelaxedv()
  call void @_ZL47TestAtomic128CompareExchangeStrongAcqRelRelaxedv()
  call void @_ZL47TestAtomic128CompareExchangeStrongAcqRelAcquirev()
  call void @_ZL47TestAtomic128CompareExchangeStrongSeqCstRelaxedv()
  call void @_ZL47TestAtomic128CompareExchangeStrongSeqCstAcquirev()
  call void @_ZL46TestAtomic128CompareExchangeStrongSeqCstSeqCstv()
  call void @_ZL41TestAtomic128CompareExchangeStrongRelaxedv()
  call void @_ZL41TestAtomic128CompareExchangeStrongAcquirev()
  call void @_ZL41TestAtomic128CompareExchangeStrongReleasev()
  call void @_ZL40TestAtomic128CompareExchangeStrongAcqRelv()
  call void @_ZL40TestAtomic128CompareExchangeStrongSeqCstv()
  call void @_ZL34TestAtomic128CompareExchangeStrongv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU32FetchAddOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU32FetchAddRelaxedv()
  call void @_ZL28TestAtomicU32FetchAddAcquirev()
  call void @_ZL28TestAtomicU32FetchAddReleasev()
  call void @_ZL27TestAtomicU32FetchAddAcqRelv()
  call void @_ZL27TestAtomicU32FetchAddSeqCstv()
  call void @_ZL21TestAtomicU32FetchAddv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU64FetchAddOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU64FetchAddRelaxedv()
  call void @_ZL28TestAtomicU64FetchAddAcquirev()
  call void @_ZL28TestAtomicU64FetchAddReleasev()
  call void @_ZL27TestAtomicU64FetchAddAcqRelv()
  call void @_ZL27TestAtomicU64FetchAddSeqCstv()
  call void @_ZL21TestAtomicU64FetchAddv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomic128FetchAddOrdersv() #1 {
entry:
  call void @_ZL28TestAtomic128FetchAddRelaxedv()
  call void @_ZL28TestAtomic128FetchAddAcquirev()
  call void @_ZL28TestAtomic128FetchAddReleasev()
  call void @_ZL27TestAtomic128FetchAddAcqRelv()
  call void @_ZL27TestAtomic128FetchAddSeqCstv()
  call void @_ZL21TestAtomic128FetchAddv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU32AddFetchOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU32AddFetchRelaxedv()
  call void @_ZL28TestAtomicU32AddFetchAcquirev()
  call void @_ZL28TestAtomicU32AddFetchReleasev()
  call void @_ZL27TestAtomicU32AddFetchAcqRelv()
  call void @_ZL27TestAtomicU32AddFetchSeqCstv()
  call void @_ZL21TestAtomicU32AddFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU64AddFetchOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU64AddFetchRelaxedv()
  call void @_ZL28TestAtomicU64AddFetchAcquirev()
  call void @_ZL28TestAtomicU64AddFetchReleasev()
  call void @_ZL27TestAtomicU64AddFetchAcqRelv()
  call void @_ZL27TestAtomicU64AddFetchSeqCstv()
  call void @_ZL21TestAtomicU64AddFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomic128AddFetchOrdersv() #1 {
entry:
  call void @_ZL28TestAtomic128AddFetchRelaxedv()
  call void @_ZL28TestAtomic128AddFetchAcquirev()
  call void @_ZL28TestAtomic128AddFetchReleasev()
  call void @_ZL27TestAtomic128AddFetchAcqRelv()
  call void @_ZL27TestAtomic128AddFetchSeqCstv()
  call void @_ZL21TestAtomic128AddFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU32FetchSubOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU32FetchSubRelaxedv()
  call void @_ZL28TestAtomicU32FetchSubAcquirev()
  call void @_ZL28TestAtomicU32FetchSubReleasev()
  call void @_ZL27TestAtomicU32FetchSubAcqRelv()
  call void @_ZL27TestAtomicU32FetchSubSeqCstv()
  call void @_ZL21TestAtomicU32FetchSubv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU64FetchSubOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU64FetchSubRelaxedv()
  call void @_ZL28TestAtomicU64FetchSubAcquirev()
  call void @_ZL28TestAtomicU64FetchSubReleasev()
  call void @_ZL27TestAtomicU64FetchSubAcqRelv()
  call void @_ZL27TestAtomicU64FetchSubSeqCstv()
  call void @_ZL21TestAtomicU64FetchSubv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomic128FetchSubOrdersv() #1 {
entry:
  call void @_ZL28TestAtomic128FetchSubRelaxedv()
  call void @_ZL28TestAtomic128FetchSubAcquirev()
  call void @_ZL28TestAtomic128FetchSubReleasev()
  call void @_ZL27TestAtomic128FetchSubAcqRelv()
  call void @_ZL27TestAtomic128FetchSubSeqCstv()
  call void @_ZL21TestAtomic128FetchSubv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU32SubFetchOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU32SubFetchRelaxedv()
  call void @_ZL28TestAtomicU32SubFetchAcquirev()
  call void @_ZL28TestAtomicU32SubFetchReleasev()
  call void @_ZL27TestAtomicU32SubFetchAcqRelv()
  call void @_ZL27TestAtomicU32SubFetchSeqCstv()
  call void @_ZL21TestAtomicU32SubFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU64SubFetchOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU64SubFetchRelaxedv()
  call void @_ZL28TestAtomicU64SubFetchAcquirev()
  call void @_ZL28TestAtomicU64SubFetchReleasev()
  call void @_ZL27TestAtomicU64SubFetchAcqRelv()
  call void @_ZL27TestAtomicU64SubFetchSeqCstv()
  call void @_ZL21TestAtomicU64SubFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomic128SubFetchOrdersv() #1 {
entry:
  call void @_ZL28TestAtomic128SubFetchRelaxedv()
  call void @_ZL28TestAtomic128SubFetchAcquirev()
  call void @_ZL28TestAtomic128SubFetchReleasev()
  call void @_ZL27TestAtomic128SubFetchAcqRelv()
  call void @_ZL27TestAtomic128SubFetchSeqCstv()
  call void @_ZL21TestAtomic128SubFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU32FetchAndOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU32FetchAndRelaxedv()
  call void @_ZL28TestAtomicU32FetchAndAcquirev()
  call void @_ZL28TestAtomicU32FetchAndReleasev()
  call void @_ZL27TestAtomicU32FetchAndAcqRelv()
  call void @_ZL27TestAtomicU32FetchAndSeqCstv()
  call void @_ZL21TestAtomicU32FetchAndv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU64FetchAndOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU64FetchAndRelaxedv()
  call void @_ZL28TestAtomicU64FetchAndAcquirev()
  call void @_ZL28TestAtomicU64FetchAndReleasev()
  call void @_ZL27TestAtomicU64FetchAndAcqRelv()
  call void @_ZL27TestAtomicU64FetchAndSeqCstv()
  call void @_ZL21TestAtomicU64FetchAndv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomic128FetchAndOrdersv() #1 {
entry:
  call void @_ZL28TestAtomic128FetchAndRelaxedv()
  call void @_ZL28TestAtomic128FetchAndAcquirev()
  call void @_ZL28TestAtomic128FetchAndReleasev()
  call void @_ZL27TestAtomic128FetchAndAcqRelv()
  call void @_ZL27TestAtomic128FetchAndSeqCstv()
  call void @_ZL21TestAtomic128FetchAndv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU32AndFetchOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU32AndFetchRelaxedv()
  call void @_ZL28TestAtomicU32AndFetchAcquirev()
  call void @_ZL28TestAtomicU32AndFetchReleasev()
  call void @_ZL27TestAtomicU32AndFetchAcqRelv()
  call void @_ZL27TestAtomicU32AndFetchSeqCstv()
  call void @_ZL21TestAtomicU32AndFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU64AndFetchOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU64AndFetchRelaxedv()
  call void @_ZL28TestAtomicU64AndFetchAcquirev()
  call void @_ZL28TestAtomicU64AndFetchReleasev()
  call void @_ZL27TestAtomicU64AndFetchAcqRelv()
  call void @_ZL27TestAtomicU64AndFetchSeqCstv()
  call void @_ZL21TestAtomicU64AndFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomic128AndFetchOrdersv() #1 {
entry:
  call void @_ZL28TestAtomic128AndFetchRelaxedv()
  call void @_ZL28TestAtomic128AndFetchAcquirev()
  call void @_ZL28TestAtomic128AndFetchReleasev()
  call void @_ZL27TestAtomic128AndFetchAcqRelv()
  call void @_ZL27TestAtomic128AndFetchSeqCstv()
  call void @_ZL21TestAtomic128AndFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL26TestAtomicU32FetchOrOrdersv() #1 {
entry:
  call void @_ZL27TestAtomicU32FetchOrRelaxedv()
  call void @_ZL27TestAtomicU32FetchOrAcquirev()
  call void @_ZL27TestAtomicU32FetchOrReleasev()
  call void @_ZL26TestAtomicU32FetchOrAcqRelv()
  call void @_ZL26TestAtomicU32FetchOrSeqCstv()
  call void @_ZL20TestAtomicU32FetchOrv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL26TestAtomicU64FetchOrOrdersv() #1 {
entry:
  call void @_ZL27TestAtomicU64FetchOrRelaxedv()
  call void @_ZL27TestAtomicU64FetchOrAcquirev()
  call void @_ZL27TestAtomicU64FetchOrReleasev()
  call void @_ZL26TestAtomicU64FetchOrAcqRelv()
  call void @_ZL26TestAtomicU64FetchOrSeqCstv()
  call void @_ZL20TestAtomicU64FetchOrv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL26TestAtomic128FetchOrOrdersv() #1 {
entry:
  call void @_ZL27TestAtomic128FetchOrRelaxedv()
  call void @_ZL27TestAtomic128FetchOrAcquirev()
  call void @_ZL27TestAtomic128FetchOrReleasev()
  call void @_ZL26TestAtomic128FetchOrAcqRelv()
  call void @_ZL26TestAtomic128FetchOrSeqCstv()
  call void @_ZL20TestAtomic128FetchOrv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL26TestAtomicU32OrFetchOrdersv() #1 {
entry:
  call void @_ZL27TestAtomicU32OrFetchRelaxedv()
  call void @_ZL27TestAtomicU32OrFetchAcquirev()
  call void @_ZL27TestAtomicU32OrFetchReleasev()
  call void @_ZL26TestAtomicU32OrFetchAcqRelv()
  call void @_ZL26TestAtomicU32OrFetchSeqCstv()
  call void @_ZL20TestAtomicU32OrFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL26TestAtomicU64OrFetchOrdersv() #1 {
entry:
  call void @_ZL27TestAtomicU64OrFetchRelaxedv()
  call void @_ZL27TestAtomicU64OrFetchAcquirev()
  call void @_ZL27TestAtomicU64OrFetchReleasev()
  call void @_ZL26TestAtomicU64OrFetchAcqRelv()
  call void @_ZL26TestAtomicU64OrFetchSeqCstv()
  call void @_ZL20TestAtomicU64OrFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL26TestAtomic128OrFetchOrdersv() #1 {
entry:
  call void @_ZL27TestAtomic128OrFetchRelaxedv()
  call void @_ZL27TestAtomic128OrFetchAcquirev()
  call void @_ZL27TestAtomic128OrFetchReleasev()
  call void @_ZL26TestAtomic128OrFetchAcqRelv()
  call void @_ZL26TestAtomic128OrFetchSeqCstv()
  call void @_ZL20TestAtomic128OrFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU32FetchXorOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU32FetchXorRelaxedv()
  call void @_ZL28TestAtomicU32FetchXorAcquirev()
  call void @_ZL28TestAtomicU32FetchXorReleasev()
  call void @_ZL27TestAtomicU32FetchXorAcqRelv()
  call void @_ZL27TestAtomicU32FetchXorSeqCstv()
  call void @_ZL21TestAtomicU32FetchXorv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU64FetchXorOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU64FetchXorRelaxedv()
  call void @_ZL28TestAtomicU64FetchXorAcquirev()
  call void @_ZL28TestAtomicU64FetchXorReleasev()
  call void @_ZL27TestAtomicU64FetchXorAcqRelv()
  call void @_ZL27TestAtomicU64FetchXorSeqCstv()
  call void @_ZL21TestAtomicU64FetchXorv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomic128FetchXorOrdersv() #1 {
entry:
  call void @_ZL28TestAtomic128FetchXorRelaxedv()
  call void @_ZL28TestAtomic128FetchXorAcquirev()
  call void @_ZL28TestAtomic128FetchXorReleasev()
  call void @_ZL27TestAtomic128FetchXorAcqRelv()
  call void @_ZL27TestAtomic128FetchXorSeqCstv()
  call void @_ZL21TestAtomic128FetchXorv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU32XorFetchOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU32XorFetchRelaxedv()
  call void @_ZL28TestAtomicU32XorFetchAcquirev()
  call void @_ZL28TestAtomicU32XorFetchReleasev()
  call void @_ZL27TestAtomicU32XorFetchAcqRelv()
  call void @_ZL27TestAtomicU32XorFetchSeqCstv()
  call void @_ZL21TestAtomicU32XorFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomicU64XorFetchOrdersv() #1 {
entry:
  call void @_ZL28TestAtomicU64XorFetchRelaxedv()
  call void @_ZL28TestAtomicU64XorFetchAcquirev()
  call void @_ZL28TestAtomicU64XorFetchReleasev()
  call void @_ZL27TestAtomicU64XorFetchAcqRelv()
  call void @_ZL27TestAtomicU64XorFetchSeqCstv()
  call void @_ZL21TestAtomicU64XorFetchv()
  ret void
}

; Function Attrs: mustprogress uwtable
define internal void @_ZL27TestAtomic128XorFetchOrdersv() #1 {
entry:
  call void @_ZL28TestAtomic128XorFetchRelaxedv()
  call void @_ZL28TestAtomic128XorFetchAcquirev()
  call void @_ZL28TestAtomic128XorFetchReleasev()
  call void @_ZL27TestAtomic128XorFetchAcqRelv()
  call void @_ZL27TestAtomic128XorFetchSeqCstv()
  call void @_ZL21TestAtomic128XorFetchv()
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL29TestAtomicU32OperatorPlusPlusv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEppEi(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 0) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL29TestAtomicU64OperatorPlusPlusv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEppEi(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i32 noundef 0) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL29TestAtomic128OperatorPlusPlusv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEppEi(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i32 noundef 0) #4
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = extractvalue { i64, i64 } %call, 0
  store i64 %1, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = extractvalue { i64, i64 } %call, 1
  store i64 %3, ptr %2, align 8
  %4 = load i128, ptr %coerce, align 16
  store i128 %4, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %5 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %5) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL29TestAtomicU32PlusPlusOperatorv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEppEv(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL29TestAtomicU64PlusPlusOperatorv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEppEv(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL29TestAtomic128PlusPlusOperatorv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEppEv(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = extractvalue { i64, i64 } %call, 0
  store i64 %1, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = extractvalue { i64, i64 } %call, 1
  store i64 %3, ptr %2, align 8
  %4 = load i128, ptr %coerce, align 16
  store i128 %4, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %5 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %5) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL31TestAtomicU32OperatorMinusMinusv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEmmEi(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 0) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL31TestAtomicU64OperatorMinusMinusv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEmmEi(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i32 noundef 0) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL31TestAtomic128OperatorMinusMinusv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEmmEi(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i32 noundef 0) #4
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = extractvalue { i64, i64 } %call, 0
  store i64 %1, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = extractvalue { i64, i64 } %call, 1
  store i64 %3, ptr %2, align 8
  %4 = load i128, ptr %coerce, align 16
  store i128 %4, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %5 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %5) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL31TestAtomicU32MinusMinusOperatorv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEmmEv(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL31TestAtomicU64MinusMinusOperatorv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEmmEv(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL31TestAtomic128MinusMinusOperatorv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEmmEv(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = extractvalue { i64, i64 } %call, 0
  store i64 %1, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = extractvalue { i64, i64 } %call, 1
  store i64 %3, ptr %2, align 8
  %4 = load i128, ptr %coerce, align 16
  store i128 %4, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %5 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %5) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL35TestAtomicU32OperatorPlusAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEpLEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL35TestAtomicU64OperatorPlusAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEpLEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL35TestAtomic128OperatorPlusAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEpLEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL36TestAtomicU32OperatorMinusAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEmIEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL36TestAtomicU64OperatorMinusAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEmIEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL36TestAtomic128OperatorMinusAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEmIEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL34TestAtomicU32OperatorAndAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEaNEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL34TestAtomicU64OperatorAndAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEaNEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL34TestAtomic128OperatorAndAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEaNEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL33TestAtomicU32OperatorOrAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEoREj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL33TestAtomicU64OperatorOrAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEoREm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL33TestAtomic128OperatorOrAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEoREo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL34TestAtomicU32OperatorXorAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEeOEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL34TestAtomicU64OperatorXorAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEeOEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL34TestAtomic128OperatorXorAssignmentv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEeOEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicSignalFenceRelaxedv() #0 {
entry:
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicSignalFenceAcquirev() #0 {
entry:
  fence syncscope("singlethread") acquire
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicSignalFenceReleasev() #0 {
entry:
  fence syncscope("singlethread") release
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicSignalFenceAcqRelv() #0 {
entry:
  fence syncscope("singlethread") acq_rel
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicSignalFenceSeqCstv() #0 {
entry:
  fence syncscope("singlethread") seq_cst
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicThreadFenceRelaxedv() #0 {
entry:
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicThreadFenceAcquirev() #0 {
entry:
  fence acquire
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicThreadFenceReleasev() #0 {
entry:
  fence release
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicThreadFenceAcqRelv() #0 {
entry:
  fence acq_rel
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicThreadFenceSeqCstv() #0 {
entry:
  call void asm sideeffect "lock; addl $$0, -8(%rsp)", "~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"() #4, !srcloc !6
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicPointerReadDependsv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.21", align 8
  %p = alloca ptr, align 8
  call void @_ZN5eastl6atomicIPvvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef ptr @_ZN5eastl8internal20atomic_pointer_widthIPvLj8EE4loadENS0_27memory_order_read_depends_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store ptr %call, ptr %p, align 8
  store ptr %p, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: nocallback nofree nounwind willreturn memory(argmem: readwrite)
declare void @llvm.memcpy.p0.p0.i64(ptr noalias nocapture writeonly, ptr noalias nocapture readonly, i64, i1 immarg) #2

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthIP17ReadDependsStructLj8EE5storeES3_NS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<8>::type", align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca ptr, align 8
  %fixedWidthDesired = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store ptr %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i6, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm8ELm8EE4typeEEEPT_RS4_(ptr noundef nonnull align 8 dereferenceable(8) %ret.i) #4
  %0 = load ptr, ptr %fromType.addr.i6, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIKP17ReadDependsStructEEPT_RS4_(ptr noundef nonnull align 8 dereferenceable(8) %0) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 8 %call.i, ptr align 8 %call1.i, i64 8, i1 false)
  %1 = load i64, ptr %ret.i, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  store ptr %fixedWidthDesired, ptr %fromType.addr.i, align 8
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %3 = load i64, ptr %2, align 8
  store i64 %3, ptr %valIntegral, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIP17ReadDependsStructE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call3, ptr %ptr.addr.i7, align 8
  %4 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i64, ptr %valIntegral, align 8
  store atomic volatile i64 %6, ptr %5 release, align 8
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthIPP20ReadDependsIntrusiveLj8EE5storeES4_NS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<8>::type", align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca ptr, align 8
  %fixedWidthDesired = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store ptr %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i6, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm8ELm8EE4typeEEEPT_RS4_(ptr noundef nonnull align 8 dereferenceable(8) %ret.i) #4
  %0 = load ptr, ptr %fromType.addr.i6, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIKPP20ReadDependsIntrusiveEEPT_RS5_(ptr noundef nonnull align 8 dereferenceable(8) %0) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 8 %call.i, ptr align 8 %call1.i, i64 8, i1 false)
  %1 = load i64, ptr %ret.i, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  store ptr %fixedWidthDesired, ptr %fromType.addr.i, align 8
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %3 = load i64, ptr %2, align 8
  store i64 %3, ptr %valIntegral, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIPP20ReadDependsIntrusiveE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call3, ptr %ptr.addr.i7, align 8
  %4 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i64, ptr %valIntegral, align 8
  store atomic volatile i64 %6, ptr %5 release, align 8
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal noundef i32 @_ZL30TestAtomicReadDependsIntrusivev() #0 {
entry:
  %intrusivePtr = alloca ptr, align 8
  %ptr = alloca ptr, align 8
  %a = alloca i32, align 4
  %b = alloca i32, align 4
  %c = alloca i32, align 4
  %d = alloca i32, align 4
  %call = call noundef ptr @_ZN5eastl8internal20atomic_pointer_widthIPP20ReadDependsIntrusiveLj8EE4loadENS0_27memory_order_read_depends_sE(ptr noundef nonnull align 8 dereferenceable(8) @gListHead) #4
  store ptr %call, ptr %intrusivePtr, align 8
  %0 = load ptr, ptr %intrusivePtr, align 8
  %add.ptr = getelementptr inbounds i8, ptr %0, i64 -8
  store ptr %add.ptr, ptr %ptr, align 8
  %1 = load ptr, ptr %ptr, align 8
  %a1 = getelementptr inbounds %struct.ReadDependsIntrusive, ptr %1, i32 0, i32 0
  %2 = load i32, ptr %a1, align 8
  store i32 %2, ptr %a, align 4
  %3 = load ptr, ptr %ptr, align 8
  %b2 = getelementptr inbounds %struct.ReadDependsIntrusive, ptr %3, i32 0, i32 1
  %4 = load i32, ptr %b2, align 4
  store i32 %4, ptr %b, align 4
  %5 = load ptr, ptr %ptr, align 8
  %c3 = getelementptr inbounds %struct.ReadDependsIntrusive, ptr %5, i32 0, i32 3
  %6 = load i32, ptr %c3, align 8
  store i32 %6, ptr %c, align 4
  %7 = load ptr, ptr %ptr, align 8
  %d4 = getelementptr inbounds %struct.ReadDependsIntrusive, ptr %7, i32 0, i32 4
  %8 = load i32, ptr %d4, align 4
  store i32 %8, ptr %d, align 4
  %9 = load i32, ptr %a, align 4
  %10 = load i32, ptr %b, align 4
  %add = add nsw i32 %9, %10
  %11 = load i32, ptr %c, align 4
  %add5 = add nsw i32 %add, %11
  %12 = load i32, ptr %d, align 4
  %add6 = add nsw i32 %add5, %12
  ret i32 %add6
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL33TestCompilerBarrierDataDependencyv() #0 {
entry:
  %val.addr.i2 = alloca ptr, align 8
  %val.addr.i1 = alloca ptr, align 8
  %val.addr.i = alloca ptr, align 8
  %t = alloca %struct.UserType128, align 4
  %p = alloca ptr, align 8
  %b = alloca i8, align 1
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %t, ptr align 4 @__const._ZL33TestCompilerBarrierDataDependencyv.t, i64 16, i1 false)
  store ptr %t, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  store ptr inttoptr (i64 3735928559 to ptr), ptr %p, align 8
  store ptr %p, ptr %val.addr.i2, align 8
  %1 = load ptr, ptr %val.addr.i2, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %1) #4, !srcloc !5
  store i8 0, ptr %b, align 1
  store ptr %b, ptr %val.addr.i1, align 8
  %2 = load ptr, ptr %val.addr.i1, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %2) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL38TestAtomic32LoadStoreSameAddressSeqCstv() #0 {
entry:
  %val.addr.i8 = alloca ptr, align 8
  %val.addr.i7 = alloca ptr, align 8
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %ret1 = alloca i32, align 4
  %ret2 = alloca i32, align 4
  %ret3 = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ej(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 0) #4
  %call = call noundef i32 @_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 %call, ptr %ret1, align 4
  call void @_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 4) #4
  %call3 = call noundef i32 @_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 %call3, ptr %ret2, align 4
  %call5 = call noundef i32 @_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 %call5, ptr %ret3, align 4
  call void @_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 5) #4
  store ptr %ret1, ptr %val.addr.i8, align 8
  %0 = load ptr, ptr %val.addr.i8, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  store ptr %ret2, ptr %val.addr.i7, align 8
  %1 = load ptr, ptr %val.addr.i7, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %1) #4, !srcloc !5
  store ptr %ret3, ptr %val.addr.i, align 8
  %2 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %2) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL39TestAtomic128LoadStoreSameAddressSeqCstv() #0 {
entry:
  %val.addr.i19 = alloca ptr, align 8
  %val.addr.i18 = alloca ptr, align 8
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %agg.tmp = alloca %struct.UserType128, align 4
  %ret1 = alloca %struct.UserType128, align 4
  %agg.tmp2 = alloca %struct.UserType128, align 4
  %ret2 = alloca %struct.UserType128, align 4
  %ret3 = alloca %struct.UserType128, align 4
  %agg.tmp12 = alloca %struct.UserType128, align 4
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 0, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 0, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 0, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 0, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2ES1_(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %1, i64 %3) #4
  %call = call { i64, i64 } @_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %ret1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 4
  %6 = getelementptr inbounds { i64, i64 }, ptr %ret1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 4
  %a3 = getelementptr inbounds %struct.UserType128, ptr %agg.tmp2, i32 0, i32 0
  store i32 1, ptr %a3, align 4
  %b4 = getelementptr inbounds %struct.UserType128, ptr %agg.tmp2, i32 0, i32 1
  store i32 0, ptr %b4, align 4
  %c5 = getelementptr inbounds %struct.UserType128, ptr %agg.tmp2, i32 0, i32 2
  store i32 2, ptr %c5, align 4
  %d6 = getelementptr inbounds %struct.UserType128, ptr %agg.tmp2, i32 0, i32 3
  store i32 4, ptr %d6, align 4
  %8 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp2, i32 0, i32 0
  %9 = load i64, ptr %8, align 4
  %10 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp2, i32 0, i32 1
  %11 = load i64, ptr %10, align 4
  call void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_NS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %9, i64 %11) #4
  %call9 = call { i64, i64 } @_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %12 = getelementptr inbounds { i64, i64 }, ptr %ret2, i32 0, i32 0
  %13 = extractvalue { i64, i64 } %call9, 0
  store i64 %13, ptr %12, align 4
  %14 = getelementptr inbounds { i64, i64 }, ptr %ret2, i32 0, i32 1
  %15 = extractvalue { i64, i64 } %call9, 1
  store i64 %15, ptr %14, align 4
  %call11 = call { i64, i64 } @_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %16 = getelementptr inbounds { i64, i64 }, ptr %ret3, i32 0, i32 0
  %17 = extractvalue { i64, i64 } %call11, 0
  store i64 %17, ptr %16, align 4
  %18 = getelementptr inbounds { i64, i64 }, ptr %ret3, i32 0, i32 1
  %19 = extractvalue { i64, i64 } %call11, 1
  store i64 %19, ptr %18, align 4
  %a13 = getelementptr inbounds %struct.UserType128, ptr %agg.tmp12, i32 0, i32 0
  store i32 1, ptr %a13, align 4
  %b14 = getelementptr inbounds %struct.UserType128, ptr %agg.tmp12, i32 0, i32 1
  store i32 1, ptr %b14, align 4
  %c15 = getelementptr inbounds %struct.UserType128, ptr %agg.tmp12, i32 0, i32 2
  store i32 2, ptr %c15, align 4
  %d16 = getelementptr inbounds %struct.UserType128, ptr %agg.tmp12, i32 0, i32 3
  store i32 4, ptr %d16, align 4
  %20 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp12, i32 0, i32 0
  %21 = load i64, ptr %20, align 4
  %22 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp12, i32 0, i32 1
  %23 = load i64, ptr %22, align 4
  call void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_NS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %21, i64 %23) #4
  store ptr %ret1, ptr %val.addr.i19, align 8
  %24 = load ptr, ptr %val.addr.i19, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %24) #4, !srcloc !5
  store ptr %ret2, ptr %val.addr.i18, align 8
  %25 = load ptr, ptr %val.addr.i18, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %25) #4, !srcloc !5
  store ptr %ret3, ptr %val.addr.i, align 8
  %26 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %26) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL25TestAtomicU32StoreRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  call void @_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL25TestAtomicU32StoreReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  call void @_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL24TestAtomicU32StoreSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  call void @_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL18TestAtomicU32Storev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  call void @_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal21atomic_integral_widthIjLj4EEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %fixedWidthDesired = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i6, align 8
  %0 = load ptr, ptr %fromType.addr.i6, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  store ptr %fixedWidthDesired, ptr %fromType.addr.i, align 8
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %3 = load i32, ptr %2, align 4
  store i32 %3, ptr %valIntegral, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call3, ptr %ptr.addr.i7, align 8
  %4 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i32, ptr %valIntegral, align 4
  store atomic volatile i32 %6, ptr %5 monotonic, align 4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal21atomic_integral_widthIjLj4EEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal20atomic_integral_baseIjLj4EEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal20atomic_integral_baseIjLj4EEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal17atomic_base_widthIjLj4EEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthIjLj4EEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal19atomic_size_alignedIjEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal19atomic_size_alignedIjEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned.7", ptr %this1, i32 0, i32 0
  store i32 0, ptr %mAtomic, align 4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned.7", ptr %this1, i32 0, i32 0
  %call = call noundef ptr @_ZN5eastl9addressofIjEEPT_RS1_(ptr noundef nonnull align 4 dereferenceable(4) %mAtomic) #4
  ret ptr %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofIjEEPT_RS1_(ptr noundef nonnull align 4 dereferenceable(4) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %fixedWidthDesired = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i6, align 8
  %0 = load ptr, ptr %fromType.addr.i6, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  store ptr %fixedWidthDesired, ptr %fromType.addr.i, align 8
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %3 = load i32, ptr %2, align 4
  store i32 %3, ptr %valIntegral, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call3, ptr %ptr.addr.i7, align 8
  %4 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i32, ptr %valIntegral, align 4
  store atomic volatile i32 %6, ptr %5 release, align 4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %fixedWidthDesired = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i6, align 8
  %0 = load ptr, ptr %fromType.addr.i6, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  store ptr %fixedWidthDesired, ptr %fromType.addr.i, align 8
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %3 = load i32, ptr %2, align 4
  store i32 %3, ptr %valIntegral, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call3, ptr %ptr.addr.i7, align 8
  %4 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i32, ptr %valIntegral, align 4
  store atomic volatile i32 %6, ptr %5 seq_cst, align 4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %fixedWidthDesired = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i6, align 8
  %0 = load ptr, ptr %fromType.addr.i6, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  store ptr %fixedWidthDesired, ptr %fromType.addr.i, align 8
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %3 = load i32, ptr %2, align 4
  store i32 %3, ptr %valIntegral, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call3, ptr %ptr.addr.i7, align 8
  %4 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i32, ptr %valIntegral, align 4
  store atomic volatile i32 %6, ptr %5 seq_cst, align 4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL25TestAtomicU64StoreRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  call void @_ZN5eastl8internal17atomic_base_widthImLj8EE5storeEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL25TestAtomicU64StoreReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  call void @_ZN5eastl8internal17atomic_base_widthImLj8EE5storeEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL24TestAtomicU64StoreSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  call void @_ZN5eastl8internal17atomic_base_widthImLj8EE5storeEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL18TestAtomicU64Storev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  call void @_ZN5eastl8internal17atomic_base_widthImLj8EE5storeEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal21atomic_integral_widthImLj8EEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthImLj8EE5storeEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %fixedWidthDesired = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i6, align 8
  %0 = load ptr, ptr %fromType.addr.i6, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  store ptr %fixedWidthDesired, ptr %fromType.addr.i, align 8
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %3 = load i64, ptr %2, align 8
  store i64 %3, ptr %valIntegral, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call3, ptr %ptr.addr.i7, align 8
  %4 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i64, ptr %valIntegral, align 8
  store atomic volatile i64 %6, ptr %5 monotonic, align 8
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal21atomic_integral_widthImLj8EEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal20atomic_integral_baseImLj8EEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal20atomic_integral_baseImLj8EEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal17atomic_base_widthImLj8EEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthImLj8EEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal19atomic_size_alignedImEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal19atomic_size_alignedImEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned.12", ptr %this1, i32 0, i32 0
  store i64 0, ptr %mAtomic, align 8
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned.12", ptr %this1, i32 0, i32 0
  %call = call noundef ptr @_ZN5eastl9addressofImEEPT_RS1_(ptr noundef nonnull align 8 dereferenceable(8) %mAtomic) #4
  ret ptr %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofImEEPT_RS1_(ptr noundef nonnull align 8 dereferenceable(8) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthImLj8EE5storeEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %fixedWidthDesired = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i6, align 8
  %0 = load ptr, ptr %fromType.addr.i6, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  store ptr %fixedWidthDesired, ptr %fromType.addr.i, align 8
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %3 = load i64, ptr %2, align 8
  store i64 %3, ptr %valIntegral, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call3, ptr %ptr.addr.i7, align 8
  %4 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i64, ptr %valIntegral, align 8
  store atomic volatile i64 %6, ptr %5 release, align 8
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthImLj8EE5storeEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %fixedWidthDesired = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i6, align 8
  %0 = load ptr, ptr %fromType.addr.i6, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  store ptr %fixedWidthDesired, ptr %fromType.addr.i, align 8
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %3 = load i64, ptr %2, align 8
  store i64 %3, ptr %valIntegral, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call3, ptr %ptr.addr.i7, align 8
  %4 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i64, ptr %valIntegral, align 8
  store atomic volatile i64 %6, ptr %5 seq_cst, align 8
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthImLj8EE5storeEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %fixedWidthDesired = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i6, align 8
  %0 = load ptr, ptr %fromType.addr.i6, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  store ptr %fixedWidthDesired, ptr %fromType.addr.i, align 8
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %3 = load i64, ptr %2, align 8
  store i64 %3, ptr %valIntegral, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call3, ptr %ptr.addr.i7, align 8
  %4 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i64, ptr %valIntegral, align 8
  store atomic volatile i64 %6, ptr %5 seq_cst, align 8
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL25TestAtomic128StoreRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  call void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_NS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %1, i64 %3) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL25TestAtomic128StoreReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  call void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_NS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %1, i64 %3) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL24TestAtomic128StoreSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  call void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_NS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %1, i64 %3) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL18TestAtomic128Storev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  call void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %1, i64 %3) #4
  store ptr %atomic, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_NS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %exchange128 = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call2, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %11 = load i128, ptr %10, align 16
  store i128 %11, ptr %exchange128, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  store ptr %exchange128, ptr %ptr.addr.i25, align 8
  %12 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  store ptr %exchange128, ptr %ptr.addr.i24, align 8
  %13 = load ptr, ptr %ptr.addr.i24, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %13, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %14, ptr %ptr.addr.i26, align 8
  %15 = load ptr, ptr %ptr.addr.i26, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %16, i64 0
  %17 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i22, align 8
  %18 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %18, i64 1
  %19 = load i64, ptr %arrayidx13, align 8
  store ptr %exchange128, ptr %ptr.addr.i21, align 8
  %20 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %20, i64 0
  %21 = load i64, ptr %arrayidx15, align 8
  store ptr %exchange128, ptr %ptr.addr.i20, align 8
  %22 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %22, i64 1
  %23 = load i64, ptr %arrayidx17, align 8
  %24 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %15, ptr elementtype(i8) %cmpxchgRet, i64 %17, i64 %19, i64 %21, i64 %23, ptr elementtype(i128) %15) #4, !srcloc !7
  %asmresult = extractvalue { i64, i64 } %24, 0
  %asmresult18 = extractvalue { i64, i64 } %24, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult18, ptr %arrayidx6, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %25 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %25 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !8

do.end:                                           ; preds = %do.cond
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal19atomic_size_alignedI11UserType128EC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal19atomic_size_alignedI11UserType128EC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned.15", ptr %this1, i32 0, i32 0
  %a = getelementptr inbounds %struct.UserType128, ptr %mAtomic, i32 0, i32 0
  store i32 0, ptr %a, align 16
  %b = getelementptr inbounds %struct.UserType128, ptr %mAtomic, i32 0, i32 1
  store i32 0, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %mAtomic, i32 0, i32 2
  store i32 0, ptr %c, align 8
  %d = getelementptr inbounds %struct.UserType128, ptr %mAtomic, i32 0, i32 3
  store i32 0, ptr %d, align 4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned.15", ptr %this1, i32 0, i32 0
  %call = call noundef ptr @_ZN5eastl9addressofI11UserType128EEPT_RS2_(ptr noundef nonnull align 4 dereferenceable(16) %mAtomic) #4
  ret ptr %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofI11UserType128EEPT_RS2_(ptr noundef nonnull align 4 dereferenceable(16) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_NS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %exchange128 = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call2, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %11 = load i128, ptr %10, align 16
  store i128 %11, ptr %exchange128, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  store ptr %exchange128, ptr %ptr.addr.i25, align 8
  %12 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  store ptr %exchange128, ptr %ptr.addr.i24, align 8
  %13 = load ptr, ptr %ptr.addr.i24, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %13, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %14, ptr %ptr.addr.i26, align 8
  %15 = load ptr, ptr %ptr.addr.i26, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %16, i64 0
  %17 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i22, align 8
  %18 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %18, i64 1
  %19 = load i64, ptr %arrayidx13, align 8
  store ptr %exchange128, ptr %ptr.addr.i21, align 8
  %20 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %20, i64 0
  %21 = load i64, ptr %arrayidx15, align 8
  store ptr %exchange128, ptr %ptr.addr.i20, align 8
  %22 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %22, i64 1
  %23 = load i64, ptr %arrayidx17, align 8
  %24 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %15, ptr elementtype(i8) %cmpxchgRet, i64 %17, i64 %19, i64 %21, i64 %23, ptr elementtype(i128) %15) #4, !srcloc !10
  %asmresult = extractvalue { i64, i64 } %24, 0
  %asmresult18 = extractvalue { i64, i64 } %24, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult18, ptr %arrayidx6, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %25 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %25 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !11

do.end:                                           ; preds = %do.cond
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_NS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %exchange128 = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call2, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %11 = load i128, ptr %10, align 16
  store i128 %11, ptr %exchange128, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  store ptr %exchange128, ptr %ptr.addr.i25, align 8
  %12 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  store ptr %exchange128, ptr %ptr.addr.i24, align 8
  %13 = load ptr, ptr %ptr.addr.i24, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %13, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %14, ptr %ptr.addr.i26, align 8
  %15 = load ptr, ptr %ptr.addr.i26, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %16, i64 0
  %17 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i22, align 8
  %18 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %18, i64 1
  %19 = load i64, ptr %arrayidx13, align 8
  store ptr %exchange128, ptr %ptr.addr.i21, align 8
  %20 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %20, i64 0
  %21 = load i64, ptr %arrayidx15, align 8
  store ptr %exchange128, ptr %ptr.addr.i20, align 8
  %22 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %22, i64 1
  %23 = load i64, ptr %arrayidx17, align 8
  %24 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %15, ptr elementtype(i8) %cmpxchgRet, i64 %17, i64 %19, i64 %21, i64 %23, ptr elementtype(i128) %15) #4, !srcloc !12
  %asmresult = extractvalue { i64, i64 } %24, 0
  %asmresult18 = extractvalue { i64, i64 } %24, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult18, ptr %arrayidx6, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %25 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %25 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !13

do.end:                                           ; preds = %do.cond
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %exchange128 = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call2, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %11 = load i128, ptr %10, align 16
  store i128 %11, ptr %exchange128, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  store ptr %exchange128, ptr %ptr.addr.i25, align 8
  %12 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  store ptr %exchange128, ptr %ptr.addr.i24, align 8
  %13 = load ptr, ptr %ptr.addr.i24, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %13, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %14, ptr %ptr.addr.i26, align 8
  %15 = load ptr, ptr %ptr.addr.i26, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %16, i64 0
  %17 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i22, align 8
  %18 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %18, i64 1
  %19 = load i64, ptr %arrayidx13, align 8
  store ptr %exchange128, ptr %ptr.addr.i21, align 8
  %20 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %20, i64 0
  %21 = load i64, ptr %arrayidx15, align 8
  store ptr %exchange128, ptr %ptr.addr.i20, align 8
  %22 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %22, i64 1
  %23 = load i64, ptr %arrayidx17, align 8
  %24 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %15, ptr elementtype(i8) %cmpxchgRet, i64 %17, i64 %19, i64 %21, i64 %23, ptr elementtype(i128) %15) #4, !srcloc !14
  %asmresult = extractvalue { i64, i64 } %24, 0
  %asmresult18 = extractvalue { i64, i64 } %24, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult18, ptr %arrayidx6, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %25 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %25 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !15

do.end:                                           ; preds = %do.cond
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL24TestAtomicU32LoadRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %load = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 %call, ptr %load, align 4
  store ptr %load, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL24TestAtomicU32LoadAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %load = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadENS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 %call, ptr %load, align 4
  store ptr %load, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL23TestAtomicU32LoadSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %load = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadENS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 %call, ptr %load, align 4
  store ptr %load, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL17TestAtomicU32Loadv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %load = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadEv(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 %call, ptr %load, align 4
  store ptr %load, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call, ptr %ptr.addr.i7, align 8
  %0 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %0, ptr %ptr.addr.i, align 8
  %1 = load ptr, ptr %ptr.addr.i, align 8
  %2 = load atomic volatile i32, ptr %1 monotonic, align 4
  store i32 %2, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i6, align 8
  %3 = load ptr, ptr %fromType.addr.i6, align 8
  %4 = load i32, ptr %3, align 4
  store i32 %4, ptr %retVal, align 4
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %5 = load ptr, ptr %fromType.addr.i, align 8
  %6 = load i32, ptr %5, align 4
  ret i32 %6
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadENS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call, ptr %ptr.addr.i7, align 8
  %0 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %0, ptr %ptr.addr.i, align 8
  %1 = load ptr, ptr %ptr.addr.i, align 8
  %2 = load atomic volatile i32, ptr %1 acquire, align 4
  store i32 %2, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i6, align 8
  %3 = load ptr, ptr %fromType.addr.i6, align 8
  %4 = load i32, ptr %3, align 4
  store i32 %4, ptr %retVal, align 4
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %5 = load ptr, ptr %fromType.addr.i, align 8
  %6 = load i32, ptr %5, align 4
  ret i32 %6
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadENS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call, ptr %ptr.addr.i7, align 8
  %0 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %0, ptr %ptr.addr.i, align 8
  %1 = load ptr, ptr %ptr.addr.i, align 8
  %2 = load atomic volatile i32, ptr %1 seq_cst, align 4
  store i32 %2, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i6, align 8
  %3 = load ptr, ptr %fromType.addr.i6, align 8
  %4 = load i32, ptr %3, align 4
  store i32 %4, ptr %retVal, align 4
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %5 = load ptr, ptr %fromType.addr.i, align 8
  %6 = load i32, ptr %5, align 4
  ret i32 %6
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadEv(ptr noundef nonnull align 4 dereferenceable(4) %this) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call, ptr %ptr.addr.i7, align 8
  %0 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %0, ptr %ptr.addr.i, align 8
  %1 = load ptr, ptr %ptr.addr.i, align 8
  %2 = load atomic volatile i32, ptr %1 seq_cst, align 4
  store i32 %2, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i6, align 8
  %3 = load ptr, ptr %fromType.addr.i6, align 8
  %4 = load i32, ptr %3, align 4
  store i32 %4, ptr %retVal, align 4
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %5 = load ptr, ptr %fromType.addr.i, align 8
  %6 = load i32, ptr %5, align 4
  ret i32 %6
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL24TestAtomicU64LoadRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %load = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZNK5eastl8internal17atomic_base_widthImLj8EE4loadENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 %call, ptr %load, align 8
  store ptr %load, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL24TestAtomicU64LoadAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %load = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZNK5eastl8internal17atomic_base_widthImLj8EE4loadENS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 %call, ptr %load, align 8
  store ptr %load, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL23TestAtomicU64LoadSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %load = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZNK5eastl8internal17atomic_base_widthImLj8EE4loadENS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 %call, ptr %load, align 8
  store ptr %load, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL17TestAtomicU64Loadv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %load = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZNK5eastl8internal17atomic_base_widthImLj8EE4loadEv(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 %call, ptr %load, align 8
  store ptr %load, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZNK5eastl8internal17atomic_base_widthImLj8EE4loadENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call, ptr %ptr.addr.i7, align 8
  %0 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %0, ptr %ptr.addr.i, align 8
  %1 = load ptr, ptr %ptr.addr.i, align 8
  %2 = load atomic volatile i64, ptr %1 monotonic, align 8
  store i64 %2, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i6, align 8
  %3 = load ptr, ptr %fromType.addr.i6, align 8
  %4 = load i64, ptr %3, align 8
  store i64 %4, ptr %retVal, align 8
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %5 = load ptr, ptr %fromType.addr.i, align 8
  %6 = load i64, ptr %5, align 8
  ret i64 %6
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZNK5eastl8internal17atomic_base_widthImLj8EE4loadENS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call, ptr %ptr.addr.i7, align 8
  %0 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %0, ptr %ptr.addr.i, align 8
  %1 = load ptr, ptr %ptr.addr.i, align 8
  %2 = load atomic volatile i64, ptr %1 acquire, align 8
  store i64 %2, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i6, align 8
  %3 = load ptr, ptr %fromType.addr.i6, align 8
  %4 = load i64, ptr %3, align 8
  store i64 %4, ptr %retVal, align 8
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %5 = load ptr, ptr %fromType.addr.i, align 8
  %6 = load i64, ptr %5, align 8
  ret i64 %6
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZNK5eastl8internal17atomic_base_widthImLj8EE4loadENS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call, ptr %ptr.addr.i7, align 8
  %0 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %0, ptr %ptr.addr.i, align 8
  %1 = load ptr, ptr %ptr.addr.i, align 8
  %2 = load atomic volatile i64, ptr %1 seq_cst, align 8
  store i64 %2, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i6, align 8
  %3 = load ptr, ptr %fromType.addr.i6, align 8
  %4 = load i64, ptr %3, align 8
  store i64 %4, ptr %retVal, align 8
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %5 = load ptr, ptr %fromType.addr.i, align 8
  %6 = load i64, ptr %5, align 8
  ret i64 %6
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZNK5eastl8internal17atomic_base_widthImLj8EE4loadEv(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %ptr.addr.i7 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i6 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call, ptr %ptr.addr.i7, align 8
  %0 = load ptr, ptr %ptr.addr.i7, align 8
  store ptr %0, ptr %ptr.addr.i, align 8
  %1 = load ptr, ptr %ptr.addr.i, align 8
  %2 = load atomic volatile i64, ptr %1 seq_cst, align 8
  store i64 %2, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i6, align 8
  %3 = load ptr, ptr %fromType.addr.i6, align 8
  %4 = load i64, ptr %3, align 8
  store i64 %4, ptr %retVal, align 8
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %5 = load ptr, ptr %fromType.addr.i, align 8
  %6 = load i64, ptr %5, align 8
  ret i64 %6
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL24TestAtomic128LoadRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %load = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %call = call { i64, i64 } @_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %0 = getelementptr inbounds { i64, i64 }, ptr %load, i32 0, i32 0
  %1 = extractvalue { i64, i64 } %call, 0
  store i64 %1, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %load, i32 0, i32 1
  %3 = extractvalue { i64, i64 } %call, 1
  store i64 %3, ptr %2, align 4
  store ptr %load, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL24TestAtomic128LoadAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %load = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %call = call { i64, i64 } @_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadENS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %0 = getelementptr inbounds { i64, i64 }, ptr %load, i32 0, i32 0
  %1 = extractvalue { i64, i64 } %call, 0
  store i64 %1, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %load, i32 0, i32 1
  %3 = extractvalue { i64, i64 } %call, 1
  store i64 %3, ptr %2, align 4
  store ptr %load, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL23TestAtomic128LoadSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %load = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %call = call { i64, i64 } @_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadENS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %0 = getelementptr inbounds { i64, i64 }, ptr %load, i32 0, i32 0
  %1 = extractvalue { i64, i64 } %call, 0
  store i64 %1, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %load, i32 0, i32 1
  %3 = extractvalue { i64, i64 } %call, 1
  store i64 %3, ptr %2, align 4
  store ptr %load, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL17TestAtomic128Loadv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %load = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %call = call { i64, i64 } @_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadEv(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %0 = getelementptr inbounds { i64, i64 }, ptr %load, i32 0, i32 0
  %1 = extractvalue { i64, i64 } %call, 0
  store i64 %1, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %load, i32 0, i32 1
  %3 = extractvalue { i64, i64 } %call, 1
  store i64 %3, ptr %2, align 4
  store ptr %load, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local { i64, i64 } @_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this) #0 comdat align 2 {
entry:
  %retval.i25 = alloca %struct.UserType128, align 4
  %fromType.addr.i26 = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 4>::type", align 4
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %retVal = alloca i128, align 16
  %expected = alloca i128, align 16
  %coerce = alloca i128, align 16
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store i128 0, ptr %expected, align 16
  store ptr %expected, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i128, ptr %0, align 16
  store i128 %1, ptr %retval.i, align 16
  %2 = load { i64, i64 }, ptr %retval.i, align 16
  %3 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %4 = extractvalue { i64, i64 } %2, 0
  store i64 %4, ptr %3, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %6 = extractvalue { i64, i64 } %2, 1
  store i64 %6, ptr %5, align 8
  %7 = load i128, ptr %coerce, align 16
  store i128 %7, ptr %retVal, align 16
  store ptr %retVal, ptr %ptr.addr.i23, align 8
  %8 = load ptr, ptr %ptr.addr.i23, align 8
  %arrayidx = getelementptr inbounds i64, ptr %8, i64 0
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %9 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx4 = getelementptr inbounds i64, ptr %9, i64 1
  %call5 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call5, ptr %ptr.addr.i, align 8
  %10 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %12 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx9, align 8
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %14 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i19, align 8
  %16 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %16, i64 0
  %17 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %18 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %18, i64 1
  %19 = load i64, ptr %arrayidx15, align 8
  %20 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2", "={ax},={dx},=*m,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %11, i64 %13, i64 %15, i64 %17, i64 %19, ptr elementtype(i128) %11) #4, !srcloc !16
  %asmresult = extractvalue { i64, i64 } %20, 0
  %asmresult16 = extractvalue { i64, i64 } %20, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx4, align 8
  store ptr %retVal, ptr %fromType.addr.i26, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm4EE4typeEEEPT_RS4_(ptr noundef nonnull align 4 dereferenceable(16) %ret.i) #4
  %21 = load ptr, ptr %fromType.addr.i26, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIKoEEPT_RS2_(ptr noundef nonnull align 16 dereferenceable(16) %21) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %call.i, ptr align 16 %call1.i, i64 16, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %retval.i25, ptr align 4 %ret.i, i64 16, i1 false)
  %22 = load { i64, i64 }, ptr %retval.i25, align 4
  %23 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 0
  %24 = extractvalue { i64, i64 } %22, 0
  store i64 %24, ptr %23, align 4
  %25 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 1
  %26 = extractvalue { i64, i64 } %22, 1
  store i64 %26, ptr %25, align 4
  %27 = load { i64, i64 }, ptr %retval, align 4
  ret { i64, i64 } %27
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm4EE4typeEEEPT_RS4_(ptr noundef nonnull align 4 dereferenceable(16) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofIKoEEPT_RS2_(ptr noundef nonnull align 16 dereferenceable(16) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local { i64, i64 } @_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadENS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this) #0 comdat align 2 {
entry:
  %retval.i25 = alloca %struct.UserType128, align 4
  %fromType.addr.i26 = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 4>::type", align 4
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %retVal = alloca i128, align 16
  %expected = alloca i128, align 16
  %coerce = alloca i128, align 16
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store i128 0, ptr %expected, align 16
  store ptr %expected, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i128, ptr %0, align 16
  store i128 %1, ptr %retval.i, align 16
  %2 = load { i64, i64 }, ptr %retval.i, align 16
  %3 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %4 = extractvalue { i64, i64 } %2, 0
  store i64 %4, ptr %3, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %6 = extractvalue { i64, i64 } %2, 1
  store i64 %6, ptr %5, align 8
  %7 = load i128, ptr %coerce, align 16
  store i128 %7, ptr %retVal, align 16
  store ptr %retVal, ptr %ptr.addr.i23, align 8
  %8 = load ptr, ptr %ptr.addr.i23, align 8
  %arrayidx = getelementptr inbounds i64, ptr %8, i64 0
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %9 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx4 = getelementptr inbounds i64, ptr %9, i64 1
  %call5 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call5, ptr %ptr.addr.i, align 8
  %10 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %12 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx9, align 8
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %14 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i19, align 8
  %16 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %16, i64 0
  %17 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %18 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %18, i64 1
  %19 = load i64, ptr %arrayidx15, align 8
  %20 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2", "={ax},={dx},=*m,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %11, i64 %13, i64 %15, i64 %17, i64 %19, ptr elementtype(i128) %11) #4, !srcloc !17
  %asmresult = extractvalue { i64, i64 } %20, 0
  %asmresult16 = extractvalue { i64, i64 } %20, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx4, align 8
  store ptr %retVal, ptr %fromType.addr.i26, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm4EE4typeEEEPT_RS4_(ptr noundef nonnull align 4 dereferenceable(16) %ret.i) #4
  %21 = load ptr, ptr %fromType.addr.i26, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIKoEEPT_RS2_(ptr noundef nonnull align 16 dereferenceable(16) %21) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %call.i, ptr align 16 %call1.i, i64 16, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %retval.i25, ptr align 4 %ret.i, i64 16, i1 false)
  %22 = load { i64, i64 }, ptr %retval.i25, align 4
  %23 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 0
  %24 = extractvalue { i64, i64 } %22, 0
  store i64 %24, ptr %23, align 4
  %25 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 1
  %26 = extractvalue { i64, i64 } %22, 1
  store i64 %26, ptr %25, align 4
  %27 = load { i64, i64 }, ptr %retval, align 4
  ret { i64, i64 } %27
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local { i64, i64 } @_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadENS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this) #0 comdat align 2 {
entry:
  %retval.i25 = alloca %struct.UserType128, align 4
  %fromType.addr.i26 = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 4>::type", align 4
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %retVal = alloca i128, align 16
  %expected = alloca i128, align 16
  %coerce = alloca i128, align 16
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store i128 0, ptr %expected, align 16
  store ptr %expected, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i128, ptr %0, align 16
  store i128 %1, ptr %retval.i, align 16
  %2 = load { i64, i64 }, ptr %retval.i, align 16
  %3 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %4 = extractvalue { i64, i64 } %2, 0
  store i64 %4, ptr %3, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %6 = extractvalue { i64, i64 } %2, 1
  store i64 %6, ptr %5, align 8
  %7 = load i128, ptr %coerce, align 16
  store i128 %7, ptr %retVal, align 16
  store ptr %retVal, ptr %ptr.addr.i23, align 8
  %8 = load ptr, ptr %ptr.addr.i23, align 8
  %arrayidx = getelementptr inbounds i64, ptr %8, i64 0
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %9 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx4 = getelementptr inbounds i64, ptr %9, i64 1
  %call5 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call5, ptr %ptr.addr.i, align 8
  %10 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %12 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx9, align 8
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %14 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i19, align 8
  %16 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %16, i64 0
  %17 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %18 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %18, i64 1
  %19 = load i64, ptr %arrayidx15, align 8
  %20 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2", "={ax},={dx},=*m,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %11, i64 %13, i64 %15, i64 %17, i64 %19, ptr elementtype(i128) %11) #4, !srcloc !18
  %asmresult = extractvalue { i64, i64 } %20, 0
  %asmresult16 = extractvalue { i64, i64 } %20, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx4, align 8
  store ptr %retVal, ptr %fromType.addr.i26, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm4EE4typeEEEPT_RS4_(ptr noundef nonnull align 4 dereferenceable(16) %ret.i) #4
  %21 = load ptr, ptr %fromType.addr.i26, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIKoEEPT_RS2_(ptr noundef nonnull align 16 dereferenceable(16) %21) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %call.i, ptr align 16 %call1.i, i64 16, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %retval.i25, ptr align 4 %ret.i, i64 16, i1 false)
  %22 = load { i64, i64 }, ptr %retval.i25, align 4
  %23 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 0
  %24 = extractvalue { i64, i64 } %22, 0
  store i64 %24, ptr %23, align 4
  %25 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 1
  %26 = extractvalue { i64, i64 } %22, 1
  store i64 %26, ptr %25, align 4
  %27 = load { i64, i64 }, ptr %retval, align 4
  ret { i64, i64 } %27
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local { i64, i64 } @_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadEv(ptr noundef nonnull align 16 dereferenceable(16) %this) #0 comdat align 2 {
entry:
  %retval.i25 = alloca %struct.UserType128, align 4
  %fromType.addr.i26 = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 4>::type", align 4
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %retVal = alloca i128, align 16
  %expected = alloca i128, align 16
  %coerce = alloca i128, align 16
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store i128 0, ptr %expected, align 16
  store ptr %expected, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i128, ptr %0, align 16
  store i128 %1, ptr %retval.i, align 16
  %2 = load { i64, i64 }, ptr %retval.i, align 16
  %3 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %4 = extractvalue { i64, i64 } %2, 0
  store i64 %4, ptr %3, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %6 = extractvalue { i64, i64 } %2, 1
  store i64 %6, ptr %5, align 8
  %7 = load i128, ptr %coerce, align 16
  store i128 %7, ptr %retVal, align 16
  store ptr %retVal, ptr %ptr.addr.i23, align 8
  %8 = load ptr, ptr %ptr.addr.i23, align 8
  %arrayidx = getelementptr inbounds i64, ptr %8, i64 0
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %9 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx4 = getelementptr inbounds i64, ptr %9, i64 1
  %call5 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call5, ptr %ptr.addr.i, align 8
  %10 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %12 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx9, align 8
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %14 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i19, align 8
  %16 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %16, i64 0
  %17 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %18 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %18, i64 1
  %19 = load i64, ptr %arrayidx15, align 8
  %20 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2", "={ax},={dx},=*m,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %11, i64 %13, i64 %15, i64 %17, i64 %19, ptr elementtype(i128) %11) #4, !srcloc !19
  %asmresult = extractvalue { i64, i64 } %20, 0
  %asmresult16 = extractvalue { i64, i64 } %20, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx4, align 8
  store ptr %retVal, ptr %fromType.addr.i26, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm4EE4typeEEEPT_RS4_(ptr noundef nonnull align 4 dereferenceable(16) %ret.i) #4
  %21 = load ptr, ptr %fromType.addr.i26, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIKoEEPT_RS2_(ptr noundef nonnull align 16 dereferenceable(16) %21) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %call.i, ptr align 16 %call1.i, i64 16, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %retval.i25, ptr align 4 %ret.i, i64 16, i1 false)
  %22 = load { i64, i64 }, ptr %retval.i25, align 4
  %23 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 0
  %24 = extractvalue { i64, i64 } %22, 0
  store i64 %24, ptr %23, align 4
  %25 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 1
  %26 = extractvalue { i64, i64 } %22, 1
  store i64 %26, ptr %25, align 4
  %27 = load { i64, i64 }, ptr %retval, align 4
  ret { i64, i64 } %27
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32ExchangeRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %exchange = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %exchange, align 4
  store ptr %exchange, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32ExchangeAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %exchange = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %exchange, align 4
  store ptr %exchange, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32ExchangeReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %exchange = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %exchange, align 4
  store ptr %exchange, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32ExchangeAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %exchange = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %exchange, align 4
  store ptr %exchange, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32ExchangeSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %exchange = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %exchange, align 4
  store ptr %exchange, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU32Exchangev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %exchange = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %exchange, align 4
  store ptr %exchange, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i10 = alloca ptr, align 8
  %fromType.addr.i9 = alloca ptr, align 8
  %fromType.addr.i8 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %fixedWidthDesired = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i10, align 8
  %0 = load ptr, ptr %fromType.addr.i10, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  store ptr %fixedWidthDesired, ptr %fromType.addr.i9, align 8
  %2 = load ptr, ptr %fromType.addr.i9, align 8
  %3 = load i32, ptr %2, align 4
  store i32 %3, ptr %valIntegral, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call3, ptr %ptr.addr.i11, align 8
  %4 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i32, ptr %valIntegral, align 4
  %7 = atomicrmw volatile xchg ptr %5, i32 %6 monotonic, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i8, align 8
  %8 = load ptr, ptr %fromType.addr.i8, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %10 = load ptr, ptr %fromType.addr.i, align 8
  %11 = load i32, ptr %10, align 4
  ret i32 %11
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i10 = alloca ptr, align 8
  %fromType.addr.i9 = alloca ptr, align 8
  %fromType.addr.i8 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %fixedWidthDesired = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i10, align 8
  %0 = load ptr, ptr %fromType.addr.i10, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  store ptr %fixedWidthDesired, ptr %fromType.addr.i9, align 8
  %2 = load ptr, ptr %fromType.addr.i9, align 8
  %3 = load i32, ptr %2, align 4
  store i32 %3, ptr %valIntegral, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call3, ptr %ptr.addr.i11, align 8
  %4 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i32, ptr %valIntegral, align 4
  %7 = atomicrmw volatile xchg ptr %5, i32 %6 acquire, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i8, align 8
  %8 = load ptr, ptr %fromType.addr.i8, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %10 = load ptr, ptr %fromType.addr.i, align 8
  %11 = load i32, ptr %10, align 4
  ret i32 %11
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i10 = alloca ptr, align 8
  %fromType.addr.i9 = alloca ptr, align 8
  %fromType.addr.i8 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %fixedWidthDesired = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i10, align 8
  %0 = load ptr, ptr %fromType.addr.i10, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  store ptr %fixedWidthDesired, ptr %fromType.addr.i9, align 8
  %2 = load ptr, ptr %fromType.addr.i9, align 8
  %3 = load i32, ptr %2, align 4
  store i32 %3, ptr %valIntegral, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call3, ptr %ptr.addr.i11, align 8
  %4 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i32, ptr %valIntegral, align 4
  %7 = atomicrmw volatile xchg ptr %5, i32 %6 release, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i8, align 8
  %8 = load ptr, ptr %fromType.addr.i8, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %10 = load ptr, ptr %fromType.addr.i, align 8
  %11 = load i32, ptr %10, align 4
  ret i32 %11
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i10 = alloca ptr, align 8
  %fromType.addr.i9 = alloca ptr, align 8
  %fromType.addr.i8 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %fixedWidthDesired = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i10, align 8
  %0 = load ptr, ptr %fromType.addr.i10, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  store ptr %fixedWidthDesired, ptr %fromType.addr.i9, align 8
  %2 = load ptr, ptr %fromType.addr.i9, align 8
  %3 = load i32, ptr %2, align 4
  store i32 %3, ptr %valIntegral, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call3, ptr %ptr.addr.i11, align 8
  %4 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i32, ptr %valIntegral, align 4
  %7 = atomicrmw volatile xchg ptr %5, i32 %6 acq_rel, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i8, align 8
  %8 = load ptr, ptr %fromType.addr.i8, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %10 = load ptr, ptr %fromType.addr.i, align 8
  %11 = load i32, ptr %10, align 4
  ret i32 %11
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i10 = alloca ptr, align 8
  %fromType.addr.i9 = alloca ptr, align 8
  %fromType.addr.i8 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %fixedWidthDesired = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i10, align 8
  %0 = load ptr, ptr %fromType.addr.i10, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  store ptr %fixedWidthDesired, ptr %fromType.addr.i9, align 8
  %2 = load ptr, ptr %fromType.addr.i9, align 8
  %3 = load i32, ptr %2, align 4
  store i32 %3, ptr %valIntegral, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call3, ptr %ptr.addr.i11, align 8
  %4 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i32, ptr %valIntegral, align 4
  %7 = atomicrmw volatile xchg ptr %5, i32 %6 seq_cst, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i8, align 8
  %8 = load ptr, ptr %fromType.addr.i8, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %10 = load ptr, ptr %fromType.addr.i, align 8
  %11 = load i32, ptr %10, align 4
  ret i32 %11
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EE8exchangeEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i10 = alloca ptr, align 8
  %fromType.addr.i9 = alloca ptr, align 8
  %fromType.addr.i8 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %fixedWidthDesired = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i10, align 8
  %0 = load ptr, ptr %fromType.addr.i10, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  store ptr %fixedWidthDesired, ptr %fromType.addr.i9, align 8
  %2 = load ptr, ptr %fromType.addr.i9, align 8
  %3 = load i32, ptr %2, align 4
  store i32 %3, ptr %valIntegral, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call3, ptr %ptr.addr.i11, align 8
  %4 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i32, ptr %valIntegral, align 4
  %7 = atomicrmw volatile xchg ptr %5, i32 %6 seq_cst, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i8, align 8
  %8 = load ptr, ptr %fromType.addr.i8, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %10 = load ptr, ptr %fromType.addr.i, align 8
  %11 = load i32, ptr %10, align 4
  ret i32 %11
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64ExchangeRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %exchange = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %exchange, align 8
  store ptr %exchange, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64ExchangeAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %exchange = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %exchange, align 8
  store ptr %exchange, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64ExchangeReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %exchange = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %exchange, align 8
  store ptr %exchange, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64ExchangeAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %exchange = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %exchange, align 8
  store ptr %exchange, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64ExchangeSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %exchange = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %exchange, align 8
  store ptr %exchange, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU64Exchangev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %exchange = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %exchange, align 8
  store ptr %exchange, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i10 = alloca ptr, align 8
  %fromType.addr.i9 = alloca ptr, align 8
  %fromType.addr.i8 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %fixedWidthDesired = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i10, align 8
  %0 = load ptr, ptr %fromType.addr.i10, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  store ptr %fixedWidthDesired, ptr %fromType.addr.i9, align 8
  %2 = load ptr, ptr %fromType.addr.i9, align 8
  %3 = load i64, ptr %2, align 8
  store i64 %3, ptr %valIntegral, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call3, ptr %ptr.addr.i11, align 8
  %4 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i64, ptr %valIntegral, align 8
  %7 = atomicrmw volatile xchg ptr %5, i64 %6 monotonic, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i8, align 8
  %8 = load ptr, ptr %fromType.addr.i8, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %10 = load ptr, ptr %fromType.addr.i, align 8
  %11 = load i64, ptr %10, align 8
  ret i64 %11
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i10 = alloca ptr, align 8
  %fromType.addr.i9 = alloca ptr, align 8
  %fromType.addr.i8 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %fixedWidthDesired = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i10, align 8
  %0 = load ptr, ptr %fromType.addr.i10, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  store ptr %fixedWidthDesired, ptr %fromType.addr.i9, align 8
  %2 = load ptr, ptr %fromType.addr.i9, align 8
  %3 = load i64, ptr %2, align 8
  store i64 %3, ptr %valIntegral, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call3, ptr %ptr.addr.i11, align 8
  %4 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i64, ptr %valIntegral, align 8
  %7 = atomicrmw volatile xchg ptr %5, i64 %6 acquire, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i8, align 8
  %8 = load ptr, ptr %fromType.addr.i8, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %10 = load ptr, ptr %fromType.addr.i, align 8
  %11 = load i64, ptr %10, align 8
  ret i64 %11
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i10 = alloca ptr, align 8
  %fromType.addr.i9 = alloca ptr, align 8
  %fromType.addr.i8 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %fixedWidthDesired = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i10, align 8
  %0 = load ptr, ptr %fromType.addr.i10, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  store ptr %fixedWidthDesired, ptr %fromType.addr.i9, align 8
  %2 = load ptr, ptr %fromType.addr.i9, align 8
  %3 = load i64, ptr %2, align 8
  store i64 %3, ptr %valIntegral, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call3, ptr %ptr.addr.i11, align 8
  %4 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i64, ptr %valIntegral, align 8
  %7 = atomicrmw volatile xchg ptr %5, i64 %6 release, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i8, align 8
  %8 = load ptr, ptr %fromType.addr.i8, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %10 = load ptr, ptr %fromType.addr.i, align 8
  %11 = load i64, ptr %10, align 8
  ret i64 %11
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i10 = alloca ptr, align 8
  %fromType.addr.i9 = alloca ptr, align 8
  %fromType.addr.i8 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %fixedWidthDesired = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i10, align 8
  %0 = load ptr, ptr %fromType.addr.i10, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  store ptr %fixedWidthDesired, ptr %fromType.addr.i9, align 8
  %2 = load ptr, ptr %fromType.addr.i9, align 8
  %3 = load i64, ptr %2, align 8
  store i64 %3, ptr %valIntegral, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call3, ptr %ptr.addr.i11, align 8
  %4 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i64, ptr %valIntegral, align 8
  %7 = atomicrmw volatile xchg ptr %5, i64 %6 acq_rel, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i8, align 8
  %8 = load ptr, ptr %fromType.addr.i8, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %10 = load ptr, ptr %fromType.addr.i, align 8
  %11 = load i64, ptr %10, align 8
  ret i64 %11
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i10 = alloca ptr, align 8
  %fromType.addr.i9 = alloca ptr, align 8
  %fromType.addr.i8 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %fixedWidthDesired = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i10, align 8
  %0 = load ptr, ptr %fromType.addr.i10, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  store ptr %fixedWidthDesired, ptr %fromType.addr.i9, align 8
  %2 = load ptr, ptr %fromType.addr.i9, align 8
  %3 = load i64, ptr %2, align 8
  store i64 %3, ptr %valIntegral, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call3, ptr %ptr.addr.i11, align 8
  %4 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i64, ptr %valIntegral, align 8
  %7 = atomicrmw volatile xchg ptr %5, i64 %6 seq_cst, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i8, align 8
  %8 = load ptr, ptr %fromType.addr.i8, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %10 = load ptr, ptr %fromType.addr.i, align 8
  %11 = load i64, ptr %10, align 8
  ret i64 %11
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EE8exchangeEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i10 = alloca ptr, align 8
  %fromType.addr.i9 = alloca ptr, align 8
  %fromType.addr.i8 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %fixedWidthDesired = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i10, align 8
  %0 = load ptr, ptr %fromType.addr.i10, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  store ptr %fixedWidthDesired, ptr %fromType.addr.i9, align 8
  %2 = load ptr, ptr %fromType.addr.i9, align 8
  %3 = load i64, ptr %2, align 8
  store i64 %3, ptr %valIntegral, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call3, ptr %ptr.addr.i11, align 8
  %4 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %4, ptr %ptr.addr.i, align 8
  %5 = load ptr, ptr %ptr.addr.i, align 8
  %6 = load i64, ptr %valIntegral, align 8
  %7 = atomicrmw volatile xchg ptr %5, i64 %6 seq_cst, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i8, align 8
  %8 = load ptr, ptr %fromType.addr.i8, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  store ptr %retVal, ptr %fromType.addr.i, align 8
  %10 = load ptr, ptr %fromType.addr.i, align 8
  %11 = load i64, ptr %10, align 8
  ret i64 %11
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128ExchangeRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %exchange = alloca %struct.UserType128, align 4
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call { i64, i64 } @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_NS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %1, i64 %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %exchange, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 4
  %6 = getelementptr inbounds { i64, i64 }, ptr %exchange, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 4
  store ptr %exchange, ptr %val.addr.i, align 8
  %8 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %8) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128ExchangeAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %exchange = alloca %struct.UserType128, align 4
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call { i64, i64 } @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_NS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %1, i64 %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %exchange, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 4
  %6 = getelementptr inbounds { i64, i64 }, ptr %exchange, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 4
  store ptr %exchange, ptr %val.addr.i, align 8
  %8 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %8) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128ExchangeReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %exchange = alloca %struct.UserType128, align 4
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call { i64, i64 } @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_NS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %1, i64 %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %exchange, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 4
  %6 = getelementptr inbounds { i64, i64 }, ptr %exchange, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 4
  store ptr %exchange, ptr %val.addr.i, align 8
  %8 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %8) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128ExchangeAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %exchange = alloca %struct.UserType128, align 4
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call { i64, i64 } @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_NS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %1, i64 %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %exchange, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 4
  %6 = getelementptr inbounds { i64, i64 }, ptr %exchange, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 4
  store ptr %exchange, ptr %val.addr.i, align 8
  %8 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %8) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128ExchangeSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %exchange = alloca %struct.UserType128, align 4
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call { i64, i64 } @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_NS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %1, i64 %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %exchange, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 4
  %6 = getelementptr inbounds { i64, i64 }, ptr %exchange, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 4
  store ptr %exchange, ptr %val.addr.i, align 8
  %8 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %8) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomic128Exchangev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %exchange = alloca %struct.UserType128, align 4
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call { i64, i64 } @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 %1, i64 %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %exchange, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 4
  %6 = getelementptr inbounds { i64, i64 }, ptr %exchange, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 4
  store ptr %exchange, ptr %val.addr.i, align 8
  %8 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %8) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local { i64, i64 } @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_NS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %retval.i28 = alloca %struct.UserType128, align 4
  %fromType.addr.i29 = alloca ptr, align 8
  %ret.i30 = alloca %"struct.eastl::aligned_storage<16, 4>::type", align 4
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %retval = alloca %struct.UserType128, align 4
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %retVal = alloca i128, align 16
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call2, ptr %ptr.addr.i20, align 8
  %10 = load ptr, ptr %ptr.addr.i20, align 8
  %11 = load i128, ptr %10, align 16
  store i128 %11, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  store ptr %retVal, ptr %ptr.addr.i26, align 8
  %12 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  store ptr %retVal, ptr %ptr.addr.i25, align 8
  %13 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %13, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %14, ptr %ptr.addr.i27, align 8
  %15 = load ptr, ptr %ptr.addr.i27, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i24, align 8
  %16 = load ptr, ptr %ptr.addr.i24, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %16, i64 0
  %17 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i23, align 8
  %18 = load ptr, ptr %ptr.addr.i23, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %18, i64 1
  %19 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %20 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %20, i64 0
  %21 = load i64, ptr %arrayidx15, align 8
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %22 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %22, i64 1
  %23 = load i64, ptr %arrayidx17, align 8
  %24 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %15, ptr elementtype(i8) %cmpxchgRet, i64 %17, i64 %19, i64 %21, i64 %23, ptr elementtype(i128) %15) #4, !srcloc !20
  %asmresult = extractvalue { i64, i64 } %24, 0
  %asmresult18 = extractvalue { i64, i64 } %24, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult18, ptr %arrayidx6, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %25 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %25 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !21

do.end:                                           ; preds = %do.cond
  store ptr %retVal, ptr %fromType.addr.i29, align 8
  %call.i31 = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm4EE4typeEEEPT_RS4_(ptr noundef nonnull align 4 dereferenceable(16) %ret.i30) #4
  %26 = load ptr, ptr %fromType.addr.i29, align 8
  %call1.i32 = call noundef ptr @_ZN5eastl9addressofIKoEEPT_RS2_(ptr noundef nonnull align 16 dereferenceable(16) %26) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %call.i31, ptr align 16 %call1.i32, i64 16, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %retval.i28, ptr align 4 %ret.i30, i64 16, i1 false)
  %27 = load { i64, i64 }, ptr %retval.i28, align 4
  %28 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 0
  %29 = extractvalue { i64, i64 } %27, 0
  store i64 %29, ptr %28, align 4
  %30 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 1
  %31 = extractvalue { i64, i64 } %27, 1
  store i64 %31, ptr %30, align 4
  %32 = load { i64, i64 }, ptr %retval, align 4
  ret { i64, i64 } %32
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local { i64, i64 } @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_NS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %retval.i28 = alloca %struct.UserType128, align 4
  %fromType.addr.i29 = alloca ptr, align 8
  %ret.i30 = alloca %"struct.eastl::aligned_storage<16, 4>::type", align 4
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %retval = alloca %struct.UserType128, align 4
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %retVal = alloca i128, align 16
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call2, ptr %ptr.addr.i20, align 8
  %10 = load ptr, ptr %ptr.addr.i20, align 8
  %11 = load i128, ptr %10, align 16
  store i128 %11, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  store ptr %retVal, ptr %ptr.addr.i26, align 8
  %12 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  store ptr %retVal, ptr %ptr.addr.i25, align 8
  %13 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %13, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %14, ptr %ptr.addr.i27, align 8
  %15 = load ptr, ptr %ptr.addr.i27, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i24, align 8
  %16 = load ptr, ptr %ptr.addr.i24, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %16, i64 0
  %17 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i23, align 8
  %18 = load ptr, ptr %ptr.addr.i23, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %18, i64 1
  %19 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %20 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %20, i64 0
  %21 = load i64, ptr %arrayidx15, align 8
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %22 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %22, i64 1
  %23 = load i64, ptr %arrayidx17, align 8
  %24 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %15, ptr elementtype(i8) %cmpxchgRet, i64 %17, i64 %19, i64 %21, i64 %23, ptr elementtype(i128) %15) #4, !srcloc !22
  %asmresult = extractvalue { i64, i64 } %24, 0
  %asmresult18 = extractvalue { i64, i64 } %24, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult18, ptr %arrayidx6, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %25 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %25 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !23

do.end:                                           ; preds = %do.cond
  store ptr %retVal, ptr %fromType.addr.i29, align 8
  %call.i31 = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm4EE4typeEEEPT_RS4_(ptr noundef nonnull align 4 dereferenceable(16) %ret.i30) #4
  %26 = load ptr, ptr %fromType.addr.i29, align 8
  %call1.i32 = call noundef ptr @_ZN5eastl9addressofIKoEEPT_RS2_(ptr noundef nonnull align 16 dereferenceable(16) %26) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %call.i31, ptr align 16 %call1.i32, i64 16, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %retval.i28, ptr align 4 %ret.i30, i64 16, i1 false)
  %27 = load { i64, i64 }, ptr %retval.i28, align 4
  %28 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 0
  %29 = extractvalue { i64, i64 } %27, 0
  store i64 %29, ptr %28, align 4
  %30 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 1
  %31 = extractvalue { i64, i64 } %27, 1
  store i64 %31, ptr %30, align 4
  %32 = load { i64, i64 }, ptr %retval, align 4
  ret { i64, i64 } %32
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local { i64, i64 } @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_NS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %retval.i28 = alloca %struct.UserType128, align 4
  %fromType.addr.i29 = alloca ptr, align 8
  %ret.i30 = alloca %"struct.eastl::aligned_storage<16, 4>::type", align 4
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %retval = alloca %struct.UserType128, align 4
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %retVal = alloca i128, align 16
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call2, ptr %ptr.addr.i20, align 8
  %10 = load ptr, ptr %ptr.addr.i20, align 8
  %11 = load i128, ptr %10, align 16
  store i128 %11, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  store ptr %retVal, ptr %ptr.addr.i26, align 8
  %12 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  store ptr %retVal, ptr %ptr.addr.i25, align 8
  %13 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %13, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %14, ptr %ptr.addr.i27, align 8
  %15 = load ptr, ptr %ptr.addr.i27, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i24, align 8
  %16 = load ptr, ptr %ptr.addr.i24, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %16, i64 0
  %17 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i23, align 8
  %18 = load ptr, ptr %ptr.addr.i23, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %18, i64 1
  %19 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %20 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %20, i64 0
  %21 = load i64, ptr %arrayidx15, align 8
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %22 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %22, i64 1
  %23 = load i64, ptr %arrayidx17, align 8
  %24 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %15, ptr elementtype(i8) %cmpxchgRet, i64 %17, i64 %19, i64 %21, i64 %23, ptr elementtype(i128) %15) #4, !srcloc !24
  %asmresult = extractvalue { i64, i64 } %24, 0
  %asmresult18 = extractvalue { i64, i64 } %24, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult18, ptr %arrayidx6, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %25 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %25 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !25

do.end:                                           ; preds = %do.cond
  store ptr %retVal, ptr %fromType.addr.i29, align 8
  %call.i31 = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm4EE4typeEEEPT_RS4_(ptr noundef nonnull align 4 dereferenceable(16) %ret.i30) #4
  %26 = load ptr, ptr %fromType.addr.i29, align 8
  %call1.i32 = call noundef ptr @_ZN5eastl9addressofIKoEEPT_RS2_(ptr noundef nonnull align 16 dereferenceable(16) %26) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %call.i31, ptr align 16 %call1.i32, i64 16, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %retval.i28, ptr align 4 %ret.i30, i64 16, i1 false)
  %27 = load { i64, i64 }, ptr %retval.i28, align 4
  %28 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 0
  %29 = extractvalue { i64, i64 } %27, 0
  store i64 %29, ptr %28, align 4
  %30 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 1
  %31 = extractvalue { i64, i64 } %27, 1
  store i64 %31, ptr %30, align 4
  %32 = load { i64, i64 }, ptr %retval, align 4
  ret { i64, i64 } %32
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local { i64, i64 } @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_NS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %retval.i28 = alloca %struct.UserType128, align 4
  %fromType.addr.i29 = alloca ptr, align 8
  %ret.i30 = alloca %"struct.eastl::aligned_storage<16, 4>::type", align 4
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %retval = alloca %struct.UserType128, align 4
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %retVal = alloca i128, align 16
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call2, ptr %ptr.addr.i20, align 8
  %10 = load ptr, ptr %ptr.addr.i20, align 8
  %11 = load i128, ptr %10, align 16
  store i128 %11, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  store ptr %retVal, ptr %ptr.addr.i26, align 8
  %12 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  store ptr %retVal, ptr %ptr.addr.i25, align 8
  %13 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %13, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %14, ptr %ptr.addr.i27, align 8
  %15 = load ptr, ptr %ptr.addr.i27, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i24, align 8
  %16 = load ptr, ptr %ptr.addr.i24, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %16, i64 0
  %17 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i23, align 8
  %18 = load ptr, ptr %ptr.addr.i23, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %18, i64 1
  %19 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %20 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %20, i64 0
  %21 = load i64, ptr %arrayidx15, align 8
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %22 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %22, i64 1
  %23 = load i64, ptr %arrayidx17, align 8
  %24 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %15, ptr elementtype(i8) %cmpxchgRet, i64 %17, i64 %19, i64 %21, i64 %23, ptr elementtype(i128) %15) #4, !srcloc !26
  %asmresult = extractvalue { i64, i64 } %24, 0
  %asmresult18 = extractvalue { i64, i64 } %24, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult18, ptr %arrayidx6, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %25 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %25 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !27

do.end:                                           ; preds = %do.cond
  store ptr %retVal, ptr %fromType.addr.i29, align 8
  %call.i31 = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm4EE4typeEEEPT_RS4_(ptr noundef nonnull align 4 dereferenceable(16) %ret.i30) #4
  %26 = load ptr, ptr %fromType.addr.i29, align 8
  %call1.i32 = call noundef ptr @_ZN5eastl9addressofIKoEEPT_RS2_(ptr noundef nonnull align 16 dereferenceable(16) %26) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %call.i31, ptr align 16 %call1.i32, i64 16, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %retval.i28, ptr align 4 %ret.i30, i64 16, i1 false)
  %27 = load { i64, i64 }, ptr %retval.i28, align 4
  %28 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 0
  %29 = extractvalue { i64, i64 } %27, 0
  store i64 %29, ptr %28, align 4
  %30 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 1
  %31 = extractvalue { i64, i64 } %27, 1
  store i64 %31, ptr %30, align 4
  %32 = load { i64, i64 }, ptr %retval, align 4
  ret { i64, i64 } %32
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local { i64, i64 } @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE8exchangeES2_(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %retval.i28 = alloca %struct.UserType128, align 4
  %fromType.addr.i29 = alloca ptr, align 8
  %ret.i30 = alloca %"struct.eastl::aligned_storage<16, 4>::type", align 4
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %retval = alloca %struct.UserType128, align 4
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %retVal = alloca i128, align 16
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call2, ptr %ptr.addr.i20, align 8
  %10 = load ptr, ptr %ptr.addr.i20, align 8
  %11 = load i128, ptr %10, align 16
  store i128 %11, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  store ptr %retVal, ptr %ptr.addr.i26, align 8
  %12 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  store ptr %retVal, ptr %ptr.addr.i25, align 8
  %13 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %13, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %14, ptr %ptr.addr.i27, align 8
  %15 = load ptr, ptr %ptr.addr.i27, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i24, align 8
  %16 = load ptr, ptr %ptr.addr.i24, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %16, i64 0
  %17 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i23, align 8
  %18 = load ptr, ptr %ptr.addr.i23, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %18, i64 1
  %19 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %20 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %20, i64 0
  %21 = load i64, ptr %arrayidx15, align 8
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %22 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %22, i64 1
  %23 = load i64, ptr %arrayidx17, align 8
  %24 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %15, ptr elementtype(i8) %cmpxchgRet, i64 %17, i64 %19, i64 %21, i64 %23, ptr elementtype(i128) %15) #4, !srcloc !28
  %asmresult = extractvalue { i64, i64 } %24, 0
  %asmresult18 = extractvalue { i64, i64 } %24, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult18, ptr %arrayidx6, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %25 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %25 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !29

do.end:                                           ; preds = %do.cond
  store ptr %retVal, ptr %fromType.addr.i29, align 8
  %call.i31 = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm4EE4typeEEEPT_RS4_(ptr noundef nonnull align 4 dereferenceable(16) %ret.i30) #4
  %26 = load ptr, ptr %fromType.addr.i29, align 8
  %call1.i32 = call noundef ptr @_ZN5eastl9addressofIKoEEPT_RS2_(ptr noundef nonnull align 16 dereferenceable(16) %26) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %call.i31, ptr align 16 %call1.i32, i64 16, i1 false)
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %retval.i28, ptr align 4 %ret.i30, i64 16, i1 false)
  %27 = load { i64, i64 }, ptr %retval.i28, align 4
  %28 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 0
  %29 = extractvalue { i64, i64 } %27, 0
  store i64 %29, ptr %28, align 4
  %30 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 1
  %31 = extractvalue { i64, i64 } %27, 1
  store i64 %31, ptr %30, align 4
  %32 = load { i64, i64 }, ptr %retval, align 4
  ret { i64, i64 } %32
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZNK5eastl6atomicIjvEcvjEv(ptr noundef nonnull align 4 dereferenceable(4) %this) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef i32 @_ZNK5eastl8internal17atomic_base_widthIjLj4EE4loadENS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  ret i32 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZNK5eastl6atomicImvEcvmEv(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef i64 @_ZNK5eastl8internal17atomic_base_widthImLj8EE4loadENS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  ret i64 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local { i64, i64 } @_ZNK5eastl6atomicI11UserType128vEcvS1_Ev(ptr noundef nonnull align 16 dereferenceable(16) %this) #0 comdat align 2 {
entry:
  %retval = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call { i64, i64 } @_ZNK5eastl8internal17atomic_base_widthI11UserType128Lj16EE4loadENS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  %0 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 0
  %1 = extractvalue { i64, i64 } %call, 0
  store i64 %1, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %retval, i32 0, i32 1
  %3 = extractvalue { i64, i64 } %call, 1
  store i64 %3, ptr %2, align 4
  %4 = load { i64, i64 }, ptr %retval, align 4
  ret { i64, i64 } %4
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal17atomic_base_widthIjLj4EEaSEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i32, ptr %desired.addr, align 4
  call void @_ZN5eastl8internal17atomic_base_widthIjLj4EE5storeEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef %0) #4
  %1 = load i32, ptr %desired.addr, align 4
  ret i32 %1
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal17atomic_base_widthImLj8EEaSEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %desired) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i64, ptr %desired.addr, align 8
  call void @_ZN5eastl8internal17atomic_base_widthImLj8EE5storeEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this1, i64 noundef %0) #4
  %1 = load i64, ptr %desired.addr, align 8
  ret i64 %1
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local { i64, i64 } @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EEaSES2_(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %retval = alloca %struct.UserType128, align 4
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %agg.tmp = alloca %struct.UserType128, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %agg.tmp, ptr align 4 %desired, i64 16, i1 false)
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %3 = load i64, ptr %2, align 4
  %4 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %5 = load i64, ptr %4, align 4
  call void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE5storeES2_NS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this1, i64 %3, i64 %5) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %retval, ptr align 4 %desired, i64 16, i1 false)
  %6 = load { i64, i64 }, ptr %retval, align 4
  ret { i64, i64 } %6
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomicU32CompareExchangeWeakRelaxedRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_relaxed_sES4_(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomicU32CompareExchangeWeakAcquireRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomicU32CompareExchangeWeakAcquireAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acquire_sES4_(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomicU32CompareExchangeWeakReleaseRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_release_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL45TestAtomicU32CompareExchangeWeakAcqRelRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL45TestAtomicU32CompareExchangeWeakAcqRelAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL45TestAtomicU32CompareExchangeWeakSeqCstRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL45TestAtomicU32CompareExchangeWeakSeqCstAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL44TestAtomicU32CompareExchangeWeakSeqCstSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_seq_cst_sES4_(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL39TestAtomicU32CompareExchangeWeakRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL39TestAtomicU32CompareExchangeWeakAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL39TestAtomicU32CompareExchangeWeakReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL38TestAtomicU32CompareExchangeWeakAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL38TestAtomicU32CompareExchangeWeakSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL32TestAtomicU32CompareExchangeWeakv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_relaxed_sES4_(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 monotonic monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 acquire monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acquire_sES4_(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 acquire acquire, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_release_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 release monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 acq_rel monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 acq_rel acquire, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 seq_cst monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 seq_cst acquire, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_seq_cst_sES4_(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 seq_cst seq_cst, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 monotonic monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 acquire acquire, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 release monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 acq_rel acquire, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 seq_cst seq_cst, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE21compare_exchange_weakERjj(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg weak volatile ptr %3, i32 %8, i32 %9 seq_cst seq_cst, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomicU64CompareExchangeWeakRelaxedRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_relaxed_sES4_(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomicU64CompareExchangeWeakAcquireRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomicU64CompareExchangeWeakAcquireAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acquire_sES4_(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomicU64CompareExchangeWeakReleaseRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_release_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL45TestAtomicU64CompareExchangeWeakAcqRelRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL45TestAtomicU64CompareExchangeWeakAcqRelAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL45TestAtomicU64CompareExchangeWeakSeqCstRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL45TestAtomicU64CompareExchangeWeakSeqCstAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL44TestAtomicU64CompareExchangeWeakSeqCstSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_seq_cst_sES4_(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL39TestAtomicU64CompareExchangeWeakRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL39TestAtomicU64CompareExchangeWeakAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL39TestAtomicU64CompareExchangeWeakReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL38TestAtomicU64CompareExchangeWeakAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL38TestAtomicU64CompareExchangeWeakSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL32TestAtomicU64CompareExchangeWeakv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_relaxed_sES4_(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 monotonic monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 acquire monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acquire_sES4_(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 acquire acquire, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_release_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 release monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 acq_rel monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 acq_rel acquire, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 seq_cst monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 seq_cst acquire, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_seq_cst_sES4_(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 seq_cst seq_cst, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 monotonic monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 acquire acquire, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 release monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 acq_rel acquire, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 seq_cst seq_cst, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE21compare_exchange_weakERmm(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg weak volatile ptr %3, i64 %8, i64 %9 seq_cst seq_cst, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomic128CompareExchangeWeakRelaxedRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_relaxed_sES5_(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomic128CompareExchangeWeakAcquireRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomic128CompareExchangeWeakAcquireAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acquire_sES5_(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomic128CompareExchangeWeakReleaseRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_release_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL45TestAtomic128CompareExchangeWeakAcqRelRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL45TestAtomic128CompareExchangeWeakAcqRelAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL45TestAtomic128CompareExchangeWeakSeqCstRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL45TestAtomic128CompareExchangeWeakSeqCstAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL44TestAtomic128CompareExchangeWeakSeqCstSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_seq_cst_sES5_(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL39TestAtomic128CompareExchangeWeakRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL39TestAtomic128CompareExchangeWeakAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL39TestAtomic128CompareExchangeWeakReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL38TestAtomic128CompareExchangeWeakAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL38TestAtomic128CompareExchangeWeakSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL32TestAtomic128CompareExchangeWeakv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: nocallback nofree nounwind willreturn memory(argmem: write)
declare void @llvm.memset.p0.i64(ptr nocapture writeonly, i8, i64, i1 immarg) #3

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_relaxed_sES5_(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !30
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !31
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acquire_sES5_(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !32
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_release_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !33
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !34
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !35
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !36
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !37
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_seq_cst_sES5_(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !38
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %11, ptr %ptr.addr.i30, align 8
  %12 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i23, align 8
  %14 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %14, ptr %ptr.addr.i29, align 8
  %15 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %15, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i22, align 8
  %16 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %16, ptr %ptr.addr.i31, align 8
  %17 = load ptr, ptr %ptr.addr.i31, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %18 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i27, align 8
  %20 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx13, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i21, align 8
  %23 = load ptr, ptr %ptr.addr.i21, align 8
  store ptr %23, ptr %ptr.addr.i26, align 8
  %24 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx16 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx16, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i25, align 8
  %28 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx19 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx19, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !39
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult20 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult20, ptr %arrayidx6, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %11, ptr %ptr.addr.i30, align 8
  %12 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i23, align 8
  %14 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %14, ptr %ptr.addr.i29, align 8
  %15 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %15, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i22, align 8
  %16 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %16, ptr %ptr.addr.i31, align 8
  %17 = load ptr, ptr %ptr.addr.i31, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %18 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i27, align 8
  %20 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx13, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i21, align 8
  %23 = load ptr, ptr %ptr.addr.i21, align 8
  store ptr %23, ptr %ptr.addr.i26, align 8
  %24 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx16 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx16, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i25, align 8
  %28 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx19 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx19, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !40
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult20 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult20, ptr %arrayidx6, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %11, ptr %ptr.addr.i30, align 8
  %12 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i23, align 8
  %14 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %14, ptr %ptr.addr.i29, align 8
  %15 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %15, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i22, align 8
  %16 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %16, ptr %ptr.addr.i31, align 8
  %17 = load ptr, ptr %ptr.addr.i31, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %18 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i27, align 8
  %20 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx13, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i21, align 8
  %23 = load ptr, ptr %ptr.addr.i21, align 8
  store ptr %23, ptr %ptr.addr.i26, align 8
  %24 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx16 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx16, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i25, align 8
  %28 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx19 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx19, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !41
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult20 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult20, ptr %arrayidx6, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %11, ptr %ptr.addr.i30, align 8
  %12 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i23, align 8
  %14 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %14, ptr %ptr.addr.i29, align 8
  %15 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %15, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i22, align 8
  %16 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %16, ptr %ptr.addr.i31, align 8
  %17 = load ptr, ptr %ptr.addr.i31, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %18 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i27, align 8
  %20 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx13, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i21, align 8
  %23 = load ptr, ptr %ptr.addr.i21, align 8
  store ptr %23, ptr %ptr.addr.i26, align 8
  %24 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx16 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx16, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i25, align 8
  %28 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx19 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx19, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !42
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult20 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult20, ptr %arrayidx6, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_NS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %11, ptr %ptr.addr.i30, align 8
  %12 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i23, align 8
  %14 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %14, ptr %ptr.addr.i29, align 8
  %15 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %15, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i22, align 8
  %16 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %16, ptr %ptr.addr.i31, align 8
  %17 = load ptr, ptr %ptr.addr.i31, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %18 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i27, align 8
  %20 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx13, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i21, align 8
  %23 = load ptr, ptr %ptr.addr.i21, align 8
  store ptr %23, ptr %ptr.addr.i26, align 8
  %24 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx16 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx16, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i25, align 8
  %28 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx19 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx19, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !43
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult20 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult20, ptr %arrayidx6, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE21compare_exchange_weakERS2_S2_(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %11, ptr %ptr.addr.i30, align 8
  %12 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i23, align 8
  %14 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %14, ptr %ptr.addr.i29, align 8
  %15 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %15, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i22, align 8
  %16 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %16, ptr %ptr.addr.i31, align 8
  %17 = load ptr, ptr %ptr.addr.i31, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %18 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i27, align 8
  %20 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx13, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i21, align 8
  %23 = load ptr, ptr %ptr.addr.i21, align 8
  store ptr %23, ptr %ptr.addr.i26, align 8
  %24 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx16 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx16, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i25, align 8
  %28 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx19 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx19, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !44
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult20 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult20, ptr %arrayidx6, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL48TestAtomicU32CompareExchangeStrongRelaxedRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_relaxed_sES4_(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL48TestAtomicU32CompareExchangeStrongAcquireRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL48TestAtomicU32CompareExchangeStrongAcquireAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acquire_sES4_(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL48TestAtomicU32CompareExchangeStrongReleaseRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_release_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL47TestAtomicU32CompareExchangeStrongAcqRelRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL47TestAtomicU32CompareExchangeStrongAcqRelAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL47TestAtomicU32CompareExchangeStrongSeqCstRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL47TestAtomicU32CompareExchangeStrongSeqCstAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomicU32CompareExchangeStrongSeqCstSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_seq_cst_sES4_(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL41TestAtomicU32CompareExchangeStrongRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL41TestAtomicU32CompareExchangeStrongAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL41TestAtomicU32CompareExchangeStrongReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL40TestAtomicU32CompareExchangeStrongAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL40TestAtomicU32CompareExchangeStrongSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL34TestAtomicU32CompareExchangeStrongv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %expected = alloca i32, align 4
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  store i32 0, ptr %expected, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_relaxed_sES4_(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 monotonic monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 acquire monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acquire_sES4_(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 acquire acquire, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_release_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 release monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 acq_rel monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 acq_rel acquire, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 seq_cst monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 seq_cst acquire, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_seq_cst_sES4_(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 seq_cst seq_cst, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 monotonic monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 acquire acquire, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 release monotonic, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 acq_rel acquire, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 seq_cst seq_cst, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthIjLj4EE23compare_exchange_strongERjj(ptr noundef nonnull align 4 dereferenceable(4) %this, ptr noundef nonnull align 4 dereferenceable(4) %expected, i32 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i32, align 4
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %fixedWidthDesired, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i32, ptr %6, align 4
  %9 = load i32, ptr %7, align 4
  %10 = cmpxchg volatile ptr %3, i32 %8, i32 %9 seq_cst seq_cst, align 4
  %11 = extractvalue { i32, i1 } %10, 0
  %12 = extractvalue { i32, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i32 %11, ptr %6, align 4
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL48TestAtomicU64CompareExchangeStrongRelaxedRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_relaxed_sES4_(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL48TestAtomicU64CompareExchangeStrongAcquireRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL48TestAtomicU64CompareExchangeStrongAcquireAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acquire_sES4_(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL48TestAtomicU64CompareExchangeStrongReleaseRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_release_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL47TestAtomicU64CompareExchangeStrongAcqRelRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL47TestAtomicU64CompareExchangeStrongAcqRelAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL47TestAtomicU64CompareExchangeStrongSeqCstRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL47TestAtomicU64CompareExchangeStrongSeqCstAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomicU64CompareExchangeStrongSeqCstSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_seq_cst_sES4_(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL41TestAtomicU64CompareExchangeStrongRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL41TestAtomicU64CompareExchangeStrongAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL41TestAtomicU64CompareExchangeStrongReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL40TestAtomicU64CompareExchangeStrongAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL40TestAtomicU64CompareExchangeStrongSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL34TestAtomicU64CompareExchangeStrongv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %expected = alloca i64, align 8
  %ret = alloca i8, align 1
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  store i64 0, ptr %expected, align 8
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef 1) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_relaxed_sES4_(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 monotonic monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 acquire monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acquire_sES4_(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 acquire acquire, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_release_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 release monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 acq_rel monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 acq_rel acquire, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 seq_cst monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 seq_cst acquire, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_seq_cst_sES4_(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i14 = alloca ptr, align 8
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call3 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this2) #4
  store ptr %call3, ptr %ptr.addr.i12, align 8
  %2 = load ptr, ptr %ptr.addr.i12, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i11, align 8
  %5 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %5, ptr %ptr.addr.i14, align 8
  %6 = load ptr, ptr %ptr.addr.i14, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i13, align 8
  %7 = load ptr, ptr %ptr.addr.i13, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 seq_cst seq_cst, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool9 = zext i1 %tobool to i8
  store i8 %frombool9, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool10 = trunc i8 %14 to i1
  ret i1 %tobool10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 monotonic monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 acquire acquire, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 release monotonic, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 acq_rel acquire, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 seq_cst seq_cst, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthImLj8EE23compare_exchange_strongERmm(ptr noundef nonnull align 8 dereferenceable(8) %this, ptr noundef nonnull align 8 dereferenceable(8) %expected, i64 noundef %desired) #0 comdat align 2 {
entry:
  %ptr.addr.i13 = alloca ptr, align 8
  %ptr.addr.i12 = alloca ptr, align 8
  %ptr.addr.i11 = alloca ptr, align 8
  %ptr.addr.i10 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %desired.addr = alloca i64, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i64, align 8
  %cmpxchg.bool = alloca i8, align 1
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  store i64 %desired, ptr %desired.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired.addr, ptr %fromType.addr.i, align 8
  %0 = load ptr, ptr %fromType.addr.i, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %fixedWidthDesired, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i11, align 8
  %2 = load ptr, ptr %ptr.addr.i11, align 8
  store ptr %2, ptr %ptr.addr.i, align 8
  %3 = load ptr, ptr %ptr.addr.i, align 8
  %4 = load ptr, ptr %expected.addr, align 8
  store ptr %4, ptr %ptr.addr.i10, align 8
  %5 = load ptr, ptr %ptr.addr.i10, align 8
  store ptr %5, ptr %ptr.addr.i13, align 8
  %6 = load ptr, ptr %ptr.addr.i13, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i12, align 8
  %7 = load ptr, ptr %ptr.addr.i12, align 8
  %8 = load i64, ptr %6, align 8
  %9 = load i64, ptr %7, align 8
  %10 = cmpxchg volatile ptr %3, i64 %8, i64 %9 seq_cst seq_cst, align 8
  %11 = extractvalue { i64, i1 } %10, 0
  %12 = extractvalue { i64, i1 } %10, 1
  br i1 %12, label %cmpxchg.continue, label %cmpxchg.store_expected

cmpxchg.store_expected:                           ; preds = %entry
  store i64 %11, ptr %6, align 8
  br label %cmpxchg.continue

cmpxchg.continue:                                 ; preds = %cmpxchg.store_expected, %entry
  %frombool = zext i1 %12 to i8
  store i8 %frombool, ptr %cmpxchg.bool, align 1
  %13 = load i8, ptr %cmpxchg.bool, align 1
  %tobool = trunc i8 %13 to i1
  %frombool8 = zext i1 %tobool to i8
  store i8 %frombool8, ptr %retVal, align 1
  %14 = load i8, ptr %retVal, align 1
  %tobool9 = trunc i8 %14 to i1
  ret i1 %tobool9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL48TestAtomic128CompareExchangeStrongRelaxedRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_relaxed_sES5_(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL48TestAtomic128CompareExchangeStrongAcquireRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL48TestAtomic128CompareExchangeStrongAcquireAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acquire_sES5_(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL48TestAtomic128CompareExchangeStrongReleaseRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_release_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL47TestAtomic128CompareExchangeStrongAcqRelRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL47TestAtomic128CompareExchangeStrongAcqRelAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL47TestAtomic128CompareExchangeStrongSeqCstRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL47TestAtomic128CompareExchangeStrongSeqCstAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL46TestAtomic128CompareExchangeStrongSeqCstSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_seq_cst_sES5_(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL41TestAtomic128CompareExchangeStrongRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL41TestAtomic128CompareExchangeStrongAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL41TestAtomic128CompareExchangeStrongReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL40TestAtomic128CompareExchangeStrongAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL40TestAtomic128CompareExchangeStrongSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL34TestAtomic128CompareExchangeStrongv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.13", align 16
  %expected = alloca %struct.UserType128, align 4
  %ret = alloca i8, align 1
  %agg.tmp = alloca %struct.UserType128, align 4
  call void @_ZN5eastl6atomicI11UserType128vEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  call void @llvm.memset.p0.i64(ptr align 4 %expected, i8 0, i64 16, i1 false)
  %a = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 0
  store i32 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 1
  store i32 1, ptr %b, align 4
  %c = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 2
  store i32 1, ptr %c, align 4
  %d = getelementptr inbounds %struct.UserType128, ptr %agg.tmp, i32 0, i32 3
  store i32 1, ptr %d, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %1 = load i64, ptr %0, align 4
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %3 = load i64, ptr %2, align 4
  %call = call noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_(ptr noundef nonnull align 16 dereferenceable(16) %atomic, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %1, i64 %3) #4
  %frombool = zext i1 %call to i8
  store i8 %frombool, ptr %ret, align 1
  store ptr %ret, ptr %val.addr.i, align 8
  %4 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %4) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_relaxed_sES5_(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !45
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acquire_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !46
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acquire_sES5_(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !47
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_release_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !48
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acq_rel_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !49
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acq_rel_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !50
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_seq_cst_sENS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !51
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_seq_cst_sENS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !52
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_seq_cst_sES5_(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i32 = alloca ptr, align 8
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this2 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i25, align 8
  %11 = load ptr, ptr %ptr.addr.i25, align 8
  store ptr %11, ptr %ptr.addr.i31, align 8
  %12 = load ptr, ptr %ptr.addr.i31, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i24, align 8
  %14 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %14, ptr %ptr.addr.i30, align 8
  %15 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx7 = getelementptr inbounds i64, ptr %15, i64 1
  %call8 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call8, ptr %ptr.addr.i23, align 8
  %16 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %16, ptr %ptr.addr.i32, align 8
  %17 = load ptr, ptr %ptr.addr.i32, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i29, align 8
  %18 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx12 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx12, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %20 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx14 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx14, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i22, align 8
  %23 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %23, ptr %ptr.addr.i27, align 8
  %24 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx17 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx17, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i26, align 8
  %28 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx20 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx20, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !53
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult21 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult21, ptr %arrayidx7, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %11, ptr %ptr.addr.i30, align 8
  %12 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i23, align 8
  %14 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %14, ptr %ptr.addr.i29, align 8
  %15 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %15, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i22, align 8
  %16 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %16, ptr %ptr.addr.i31, align 8
  %17 = load ptr, ptr %ptr.addr.i31, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %18 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i27, align 8
  %20 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx13, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i21, align 8
  %23 = load ptr, ptr %ptr.addr.i21, align 8
  store ptr %23, ptr %ptr.addr.i26, align 8
  %24 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx16 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx16, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i25, align 8
  %28 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx19 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx19, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !54
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult20 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult20, ptr %arrayidx6, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %11, ptr %ptr.addr.i30, align 8
  %12 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i23, align 8
  %14 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %14, ptr %ptr.addr.i29, align 8
  %15 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %15, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i22, align 8
  %16 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %16, ptr %ptr.addr.i31, align 8
  %17 = load ptr, ptr %ptr.addr.i31, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %18 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i27, align 8
  %20 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx13, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i21, align 8
  %23 = load ptr, ptr %ptr.addr.i21, align 8
  store ptr %23, ptr %ptr.addr.i26, align 8
  %24 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx16 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx16, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i25, align 8
  %28 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx19 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx19, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !55
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult20 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult20, ptr %arrayidx6, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %11, ptr %ptr.addr.i30, align 8
  %12 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i23, align 8
  %14 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %14, ptr %ptr.addr.i29, align 8
  %15 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %15, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i22, align 8
  %16 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %16, ptr %ptr.addr.i31, align 8
  %17 = load ptr, ptr %ptr.addr.i31, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %18 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i27, align 8
  %20 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx13, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i21, align 8
  %23 = load ptr, ptr %ptr.addr.i21, align 8
  store ptr %23, ptr %ptr.addr.i26, align 8
  %24 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx16 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx16, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i25, align 8
  %28 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx19 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx19, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !56
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult20 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult20, ptr %arrayidx6, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %11, ptr %ptr.addr.i30, align 8
  %12 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i23, align 8
  %14 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %14, ptr %ptr.addr.i29, align 8
  %15 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %15, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i22, align 8
  %16 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %16, ptr %ptr.addr.i31, align 8
  %17 = load ptr, ptr %ptr.addr.i31, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %18 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i27, align 8
  %20 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx13, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i21, align 8
  %23 = load ptr, ptr %ptr.addr.i21, align 8
  store ptr %23, ptr %ptr.addr.i26, align 8
  %24 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx16 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx16, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i25, align 8
  %28 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx19 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx19, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !57
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult20 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult20, ptr %arrayidx6, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_NS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %11, ptr %ptr.addr.i30, align 8
  %12 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i23, align 8
  %14 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %14, ptr %ptr.addr.i29, align 8
  %15 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %15, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i22, align 8
  %16 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %16, ptr %ptr.addr.i31, align 8
  %17 = load ptr, ptr %ptr.addr.i31, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %18 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i27, align 8
  %20 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx13, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i21, align 8
  %23 = load ptr, ptr %ptr.addr.i21, align 8
  store ptr %23, ptr %ptr.addr.i26, align 8
  %24 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx16 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx16, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i25, align 8
  %28 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx19 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx19, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !58
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult20 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult20, ptr %arrayidx6, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef zeroext i1 @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EE23compare_exchange_strongERS2_S2_(ptr noundef nonnull align 16 dereferenceable(16) %this, ptr noundef nonnull align 4 dereferenceable(16) %expected, i64 %desired.coerce0, i64 %desired.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i31 = alloca ptr, align 8
  %ptr.addr.i30 = alloca ptr, align 8
  %ptr.addr.i29 = alloca ptr, align 8
  %ptr.addr.i28 = alloca ptr, align 8
  %ptr.addr.i27 = alloca ptr, align 8
  %ptr.addr.i26 = alloca ptr, align 8
  %ptr.addr.i25 = alloca ptr, align 8
  %ptr.addr.i24 = alloca ptr, align 8
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval.i = alloca i128, align 16
  %fromType.addr.i = alloca ptr, align 8
  %ret.i = alloca %"struct.eastl::aligned_storage<16, 16>::type", align 16
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %expected.addr = alloca ptr, align 8
  %retVal = alloca i8, align 1
  %fixedWidthDesired = alloca i128, align 16
  %coerce = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  store ptr %expected, ptr %expected.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %desired, ptr %fromType.addr.i, align 8
  %call.i = call noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm16ELm16EE4typeEEEPT_RS4_(ptr noundef nonnull align 16 dereferenceable(16) %ret.i) #4
  %2 = load ptr, ptr %fromType.addr.i, align 8
  %call1.i = call noundef ptr @_ZN5eastl9addressofIK11UserType128EEPT_RS3_(ptr noundef nonnull align 4 dereferenceable(16) %2) #4
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %call.i, ptr align 4 %call1.i, i64 16, i1 false)
  %3 = load i128, ptr %ret.i, align 16
  store i128 %3, ptr %retval.i, align 16
  %4 = load { i64, i64 }, ptr %retval.i, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %4, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %4, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce, align 16
  store i128 %9, ptr %fixedWidthDesired, align 16
  %10 = load ptr, ptr %expected.addr, align 8
  store ptr %10, ptr %ptr.addr.i24, align 8
  %11 = load ptr, ptr %ptr.addr.i24, align 8
  store ptr %11, ptr %ptr.addr.i30, align 8
  %12 = load ptr, ptr %ptr.addr.i30, align 8
  %arrayidx = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load ptr, ptr %expected.addr, align 8
  store ptr %13, ptr %ptr.addr.i23, align 8
  %14 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %14, ptr %ptr.addr.i29, align 8
  %15 = load ptr, ptr %ptr.addr.i29, align 8
  %arrayidx6 = getelementptr inbounds i64, ptr %15, i64 1
  %call7 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedI11UserType128E16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  store ptr %call7, ptr %ptr.addr.i22, align 8
  %16 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %16, ptr %ptr.addr.i31, align 8
  %17 = load ptr, ptr %ptr.addr.i31, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i28, align 8
  %18 = load ptr, ptr %ptr.addr.i28, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %18, i64 0
  %19 = load i64, ptr %arrayidx11, align 8
  store ptr %fixedWidthDesired, ptr %ptr.addr.i27, align 8
  %20 = load ptr, ptr %ptr.addr.i27, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %20, i64 1
  %21 = load i64, ptr %arrayidx13, align 8
  %22 = load ptr, ptr %expected.addr, align 8
  store ptr %22, ptr %ptr.addr.i21, align 8
  %23 = load ptr, ptr %ptr.addr.i21, align 8
  store ptr %23, ptr %ptr.addr.i26, align 8
  %24 = load ptr, ptr %ptr.addr.i26, align 8
  %arrayidx16 = getelementptr inbounds i64, ptr %24, i64 0
  %25 = load i64, ptr %arrayidx16, align 8
  %26 = load ptr, ptr %expected.addr, align 8
  store ptr %26, ptr %ptr.addr.i, align 8
  %27 = load ptr, ptr %ptr.addr.i, align 8
  store ptr %27, ptr %ptr.addr.i25, align 8
  %28 = load ptr, ptr %ptr.addr.i25, align 8
  %arrayidx19 = getelementptr inbounds i64, ptr %28, i64 1
  %29 = load i64, ptr %arrayidx19, align 8
  %30 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %17, ptr elementtype(i8) %retVal, i64 %19, i64 %21, i64 %25, i64 %29, ptr elementtype(i128) %17) #4, !srcloc !59
  %asmresult = extractvalue { i64, i64 } %30, 0
  %asmresult20 = extractvalue { i64, i64 } %30, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult20, ptr %arrayidx6, align 8
  %31 = load i8, ptr %retVal, align 1
  %tobool = trunc i8 %31 to i1
  ret i1 %tobool
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32FetchAddRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32FetchAddAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32FetchAddReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32FetchAddAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32FetchAddSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU32FetchAddv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile add ptr %2, i32 %4 monotonic, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile add ptr %2, i32 %4 acquire, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile add ptr %2, i32 %4 release, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile add ptr %2, i32 %4 acq_rel, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile add ptr %2, i32 %4 seq_cst, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile add ptr %2, i32 %4 seq_cst, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64FetchAddRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64FetchAddAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64FetchAddReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64FetchAddAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64FetchAddSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU64FetchAddv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile add ptr %2, i64 %4 monotonic, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile add ptr %2, i64 %4 acquire, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile add ptr %2, i64 %4 release, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile add ptr %2, i64 %4 acq_rel, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile add ptr %2, i64 %4 seq_cst, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile add ptr %2, i64 %4 seq_cst, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128FetchAddRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128FetchAddAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128FetchAddReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128FetchAddAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128FetchAddSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomic128FetchAddv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal21atomic_integral_widthIoLj16EEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %add = add i128 %3, %4
  store i128 %add, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !60
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !61

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal21atomic_integral_widthIoLj16EEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal20atomic_integral_baseIoLj16EEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal20atomic_integral_baseIoLj16EEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal17atomic_base_widthIoLj16EEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthIoLj16EEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal19atomic_size_alignedIoEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal19atomic_size_alignedIoEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned.20", ptr %this1, i32 0, i32 0
  store i128 0, ptr %mAtomic, align 16
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned.20", ptr %this1, i32 0, i32 0
  %call = call noundef ptr @_ZN5eastl9addressofIoEEPT_RS1_(ptr noundef nonnull align 16 dereferenceable(16) %mAtomic) #4
  ret ptr %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofIoEEPT_RS1_(ptr noundef nonnull align 16 dereferenceable(16) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %add = add i128 %3, %4
  store i128 %add, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !62
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !63

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %add = add i128 %3, %4
  store i128 %add, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !64
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !65

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %add = add i128 %3, %4
  store i128 %add, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !66
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !67

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %add = add i128 %3, %4
  store i128 %add, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !68
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !69

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %add = add i128 %3, %4
  store i128 %add, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !70
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !71

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32AddFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32AddFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32AddFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32AddFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32AddFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU32AddFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile add ptr %2, i32 %4 monotonic, align 4
  %6 = add i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile add ptr %2, i32 %4 acquire, align 4
  %6 = add i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile add ptr %2, i32 %4 release, align 4
  %6 = add i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile add ptr %2, i32 %4 acq_rel, align 4
  %6 = add i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile add ptr %2, i32 %4 seq_cst, align 4
  %6 = add i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile add ptr %2, i32 %4 seq_cst, align 4
  %6 = add i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64AddFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64AddFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64AddFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64AddFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64AddFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU64AddFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile add ptr %2, i64 %4 monotonic, align 8
  %6 = add i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile add ptr %2, i64 %4 acquire, align 8
  %6 = add i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile add ptr %2, i64 %4 release, align 8
  %6 = add i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile add ptr %2, i64 %4 acq_rel, align 8
  %6 = add i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile add ptr %2, i64 %4 seq_cst, align 8
  %6 = add i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile add ptr %2, i64 %4 seq_cst, align 8
  %6 = add i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128AddFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128AddFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128AddFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128AddFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128AddFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomic128AddFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %add = add i128 %3, %4
  store i128 %add, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !72
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !73

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %add17 = add i128 %18, %19
  store i128 %add17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %add = add i128 %3, %4
  store i128 %add, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !74
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !75

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %add17 = add i128 %18, %19
  store i128 %add17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %add = add i128 %3, %4
  store i128 %add, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !76
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !77

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %add17 = add i128 %18, %19
  store i128 %add17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %add = add i128 %3, %4
  store i128 %add, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !78
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !79

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %add17 = add i128 %18, %19
  store i128 %add17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %add = add i128 %3, %4
  store i128 %add, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !80
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !81

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %add17 = add i128 %18, %19
  store i128 %add17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %add = add i128 %3, %4
  store i128 %add, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !82
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !83

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %add17 = add i128 %18, %19
  store i128 %add17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32FetchSubRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32FetchSubAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32FetchSubReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32FetchSubAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32FetchSubSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU32FetchSubv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile sub ptr %2, i32 %4 monotonic, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile sub ptr %2, i32 %4 acquire, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile sub ptr %2, i32 %4 release, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile sub ptr %2, i32 %4 acq_rel, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile sub ptr %2, i32 %4 seq_cst, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile sub ptr %2, i32 %4 seq_cst, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64FetchSubRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64FetchSubAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64FetchSubReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64FetchSubAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64FetchSubSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU64FetchSubv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile sub ptr %2, i64 %4 monotonic, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile sub ptr %2, i64 %4 acquire, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile sub ptr %2, i64 %4 release, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile sub ptr %2, i64 %4 acq_rel, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile sub ptr %2, i64 %4 seq_cst, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile sub ptr %2, i64 %4 seq_cst, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128FetchSubRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128FetchSubAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128FetchSubReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128FetchSubAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128FetchSubSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomic128FetchSubv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %sub = sub i128 %3, %4
  store i128 %sub, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !84
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !85

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %sub = sub i128 %3, %4
  store i128 %sub, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !86
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !87

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %sub = sub i128 %3, %4
  store i128 %sub, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !88
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !89

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %sub = sub i128 %3, %4
  store i128 %sub, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !90
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !91

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %sub = sub i128 %3, %4
  store i128 %sub, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !92
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !93

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %sub = sub i128 %3, %4
  store i128 %sub, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !94
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !95

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32SubFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32SubFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32SubFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32SubFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32SubFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU32SubFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile sub ptr %2, i32 %4 monotonic, align 4
  %6 = sub i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile sub ptr %2, i32 %4 acquire, align 4
  %6 = sub i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile sub ptr %2, i32 %4 release, align 4
  %6 = sub i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile sub ptr %2, i32 %4 acq_rel, align 4
  %6 = sub i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile sub ptr %2, i32 %4 seq_cst, align 4
  %6 = sub i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile sub ptr %2, i32 %4 seq_cst, align 4
  %6 = sub i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64SubFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64SubFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64SubFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64SubFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64SubFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU64SubFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile sub ptr %2, i64 %4 monotonic, align 8
  %6 = sub i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile sub ptr %2, i64 %4 acquire, align 8
  %6 = sub i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile sub ptr %2, i64 %4 release, align 8
  %6 = sub i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile sub ptr %2, i64 %4 acq_rel, align 8
  %6 = sub i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile sub ptr %2, i64 %4 seq_cst, align 8
  %6 = sub i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile sub ptr %2, i64 %4 seq_cst, align 8
  %6 = sub i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128SubFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128SubFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128SubFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128SubFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128SubFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomic128SubFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %sub = sub i128 %3, %4
  store i128 %sub, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !96
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !97

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %sub17 = sub i128 %18, %19
  store i128 %sub17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %sub = sub i128 %3, %4
  store i128 %sub, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !98
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !99

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %sub17 = sub i128 %18, %19
  store i128 %sub17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %sub = sub i128 %3, %4
  store i128 %sub, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !100
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !101

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %sub17 = sub i128 %18, %19
  store i128 %sub17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %sub = sub i128 %3, %4
  store i128 %sub, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !102
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !103

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %sub17 = sub i128 %18, %19
  store i128 %sub17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %sub = sub i128 %3, %4
  store i128 %sub, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !104
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !105

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %sub17 = sub i128 %18, %19
  store i128 %sub17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %sub = sub i128 %3, %4
  store i128 %sub, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !106
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !107

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %sub17 = sub i128 %18, %19
  store i128 %sub17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32FetchAndRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32FetchAndAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32FetchAndReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32FetchAndAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32FetchAndSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU32FetchAndv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile and ptr %2, i32 %4 monotonic, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile and ptr %2, i32 %4 acquire, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile and ptr %2, i32 %4 release, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile and ptr %2, i32 %4 acq_rel, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile and ptr %2, i32 %4 seq_cst, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_andEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile and ptr %2, i32 %4 seq_cst, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64FetchAndRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64FetchAndAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64FetchAndReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64FetchAndAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64FetchAndSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU64FetchAndv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile and ptr %2, i64 %4 monotonic, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile and ptr %2, i64 %4 acquire, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile and ptr %2, i64 %4 release, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile and ptr %2, i64 %4 acq_rel, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile and ptr %2, i64 %4 seq_cst, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_andEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile and ptr %2, i64 %4 seq_cst, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128FetchAndRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128FetchAndAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128FetchAndReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128FetchAndAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128FetchAndSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomic128FetchAndv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %and = and i128 %3, %4
  store i128 %and, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !108
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !109

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %and = and i128 %3, %4
  store i128 %and, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !110
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !111

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %and = and i128 %3, %4
  store i128 %and, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !112
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !113

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %and = and i128 %3, %4
  store i128 %and, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !114
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !115

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %and = and i128 %3, %4
  store i128 %and, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !116
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !117

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_andEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %and = and i128 %3, %4
  store i128 %and, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !118
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !119

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32AndFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32AndFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32AndFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32AndFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32AndFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU32AndFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile and ptr %2, i32 %4 monotonic, align 4
  %6 = and i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile and ptr %2, i32 %4 acquire, align 4
  %6 = and i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile and ptr %2, i32 %4 release, align 4
  %6 = and i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile and ptr %2, i32 %4 acq_rel, align 4
  %6 = and i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile and ptr %2, i32 %4 seq_cst, align 4
  %6 = and i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile and ptr %2, i32 %4 seq_cst, align 4
  %6 = and i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64AndFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64AndFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64AndFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64AndFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64AndFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU64AndFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile and ptr %2, i64 %4 monotonic, align 8
  %6 = and i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile and ptr %2, i64 %4 acquire, align 8
  %6 = and i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile and ptr %2, i64 %4 release, align 8
  %6 = and i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile and ptr %2, i64 %4 acq_rel, align 8
  %6 = and i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile and ptr %2, i64 %4 seq_cst, align 8
  %6 = and i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile and ptr %2, i64 %4 seq_cst, align 8
  %6 = and i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128AndFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128AndFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128AndFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128AndFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128AndFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomic128AndFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %and = and i128 %3, %4
  store i128 %and, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !120
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !121

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %and17 = and i128 %18, %19
  store i128 %and17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %and = and i128 %3, %4
  store i128 %and, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !122
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !123

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %and17 = and i128 %18, %19
  store i128 %and17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %and = and i128 %3, %4
  store i128 %and, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !124
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !125

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %and17 = and i128 %18, %19
  store i128 %and17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %and = and i128 %3, %4
  store i128 %and, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !126
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !127

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %and17 = and i128 %18, %19
  store i128 %and17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %and = and i128 %3, %4
  store i128 %and, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !128
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !129

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %and17 = and i128 %18, %19
  store i128 %and17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %and = and i128 %3, %4
  store i128 %and, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !130
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !131

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %and17 = and i128 %18, %19
  store i128 %and17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32FetchOrRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32FetchOrAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32FetchOrReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomicU32FetchOrAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomicU32FetchOrSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL20TestAtomicU32FetchOrv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile or ptr %2, i32 %4 monotonic, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile or ptr %2, i32 %4 acquire, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile or ptr %2, i32 %4 release, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile or ptr %2, i32 %4 acq_rel, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile or ptr %2, i32 %4 seq_cst, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8fetch_orEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile or ptr %2, i32 %4 seq_cst, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64FetchOrRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64FetchOrAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64FetchOrReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomicU64FetchOrAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomicU64FetchOrSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL20TestAtomicU64FetchOrv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile or ptr %2, i64 %4 monotonic, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile or ptr %2, i64 %4 acquire, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile or ptr %2, i64 %4 release, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile or ptr %2, i64 %4 acq_rel, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile or ptr %2, i64 %4 seq_cst, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8fetch_orEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile or ptr %2, i64 %4 seq_cst, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128FetchOrRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128FetchOrAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128FetchOrReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomic128FetchOrAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomic128FetchOrSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL20TestAtomic128FetchOrv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %or = or i128 %3, %4
  store i128 %or, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !132
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !133

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %or = or i128 %3, %4
  store i128 %or, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !134
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !135

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %or = or i128 %3, %4
  store i128 %or, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !136
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !137

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %or = or i128 %3, %4
  store i128 %or, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !138
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !139

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %or = or i128 %3, %4
  store i128 %or, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !140
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !141

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8fetch_orEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %or = or i128 %3, %4
  store i128 %or, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !142
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !143

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32OrFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32OrFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32OrFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomicU32OrFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomicU32OrFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL20TestAtomicU32OrFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile or ptr %2, i32 %4 monotonic, align 4
  %6 = or i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile or ptr %2, i32 %4 acquire, align 4
  %6 = or i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile or ptr %2, i32 %4 release, align 4
  %6 = or i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile or ptr %2, i32 %4 acq_rel, align 4
  %6 = or i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile or ptr %2, i32 %4 seq_cst, align 4
  %6 = or i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile or ptr %2, i32 %4 seq_cst, align 4
  %6 = or i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64OrFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64OrFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64OrFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomicU64OrFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomicU64OrFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL20TestAtomicU64OrFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile or ptr %2, i64 %4 monotonic, align 8
  %6 = or i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile or ptr %2, i64 %4 acquire, align 8
  %6 = or i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile or ptr %2, i64 %4 release, align 8
  %6 = or i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile or ptr %2, i64 %4 acq_rel, align 8
  %6 = or i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile or ptr %2, i64 %4 seq_cst, align 8
  %6 = or i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile or ptr %2, i64 %4 seq_cst, align 8
  %6 = or i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128OrFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128OrFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128OrFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomic128OrFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL26TestAtomic128OrFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL20TestAtomic128OrFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %or = or i128 %3, %4
  store i128 %or, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !144
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !145

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %or17 = or i128 %18, %19
  store i128 %or17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %or = or i128 %3, %4
  store i128 %or, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !146
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !147

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %or17 = or i128 %18, %19
  store i128 %or17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %or = or i128 %3, %4
  store i128 %or, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !148
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !149

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %or17 = or i128 %18, %19
  store i128 %or17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %or = or i128 %3, %4
  store i128 %or, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !150
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !151

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %or17 = or i128 %18, %19
  store i128 %or17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %or = or i128 %3, %4
  store i128 %or, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !152
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !153

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %or17 = or i128 %18, %19
  store i128 %or17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %or = or i128 %3, %4
  store i128 %or, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !154
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !155

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %or17 = or i128 %18, %19
  store i128 %or17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32FetchXorRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32FetchXorAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32FetchXorReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32FetchXorAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32FetchXorSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU32FetchXorv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile xor ptr %2, i32 %4 monotonic, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile xor ptr %2, i32 %4 acquire, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile xor ptr %2, i32 %4 release, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile xor ptr %2, i32 %4 acq_rel, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile xor ptr %2, i32 %4 seq_cst, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_xorEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile xor ptr %2, i32 %4 seq_cst, align 4
  store i32 %5, ptr %atomic-temp, align 4
  %6 = load i32, ptr %atomic-temp, align 4
  store i32 %6, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i32, ptr %7, align 4
  store i32 %8, ptr %retVal, align 4
  %9 = load i32, ptr %retVal, align 4
  ret i32 %9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64FetchXorRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64FetchXorAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64FetchXorReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64FetchXorAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64FetchXorSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU64FetchXorv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile xor ptr %2, i64 %4 monotonic, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile xor ptr %2, i64 %4 acquire, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile xor ptr %2, i64 %4 release, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile xor ptr %2, i64 %4 acq_rel, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_xorEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile xor ptr %2, i64 %4 seq_cst, align 8
  store i64 %5, ptr %atomic-temp, align 8
  %6 = load i64, ptr %atomic-temp, align 8
  store i64 %6, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %7 = load ptr, ptr %fromType.addr.i, align 8
  %8 = load i64, ptr %7, align 8
  store i64 %8, ptr %retVal, align 8
  %9 = load i64, ptr %retVal, align 8
  ret i64 %9
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128FetchXorRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128FetchXorAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128FetchXorReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128FetchXorAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128FetchXorSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomic128FetchXorv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %xor = xor i128 %3, %4
  store i128 %xor, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !156
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !157

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %xor = xor i128 %3, %4
  store i128 %xor, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !158
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !159

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %xor = xor i128 %3, %4
  store i128 %xor, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !160
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !161

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %xor = xor i128 %3, %4
  store i128 %xor, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !162
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !163

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %xor = xor i128 %3, %4
  store i128 %xor, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !164
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !165

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_xorEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i17 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %xor = xor i128 %3, %4
  store i128 %xor, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %5 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i20, align 8
  %6 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i22, align 8
  %7 = load ptr, ptr %ptr.addr.i22, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %8 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i18, align 8
  %10 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i17, align 8
  %12 = load ptr, ptr %ptr.addr.i17, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !166
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !167

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  store i128 %18, ptr %retval, align 16
  %19 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %19
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32XorFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32XorFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU32XorFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32XorFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU32XorFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU32XorFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.5", align 4
  %val = alloca i32, align 4
  call void @_ZN5eastl6atomicIjvEC2Ev(ptr noundef nonnull align 4 dereferenceable(4) %atomic) #4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEj(ptr noundef nonnull align 4 dereferenceable(4) %atomic, i32 noundef 1) #4
  store i32 %call, ptr %val, align 4
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile xor ptr %2, i32 %4 monotonic, align 4
  %6 = xor i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_acquire_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile xor ptr %2, i32 %4 acquire, align 4
  %6 = xor i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_release_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile xor ptr %2, i32 %4 release, align 4
  %6 = xor i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile xor ptr %2, i32 %4 acq_rel, align 4
  %6 = xor i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile xor ptr %2, i32 %4 seq_cst, align 4
  %6 = xor i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  %retVal = alloca i32, align 4
  %retIntegral = alloca i32, align 4
  %valIntegral = alloca i32, align 4
  %.atomictmp = alloca i32, align 4
  %atomic-temp = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i32, ptr %0, align 4
  store i32 %1, ptr %valIntegral, align 4
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIjE16GetAtomicAddressEv(ptr noundef nonnull align 4 dereferenceable(4) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i32, ptr %valIntegral, align 4
  store i32 %3, ptr %.atomictmp, align 4
  %4 = load i32, ptr %.atomictmp, align 4
  %5 = atomicrmw volatile xor ptr %2, i32 %4 seq_cst, align 4
  %6 = xor i32 %5, %4
  store i32 %6, ptr %atomic-temp, align 4
  %7 = load i32, ptr %atomic-temp, align 4
  store i32 %7, ptr %retIntegral, align 4
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i32, ptr %8, align 4
  store i32 %9, ptr %retVal, align 4
  %10 = load i32, ptr %retVal, align 4
  ret i32 %10
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64XorFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64XorFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomicU64XorFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64XorFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomicU64XorFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomicU64XorFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.8", align 8
  %val = alloca i64, align 8
  call void @_ZN5eastl6atomicImvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %atomic) #4
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEm(ptr noundef nonnull align 8 dereferenceable(8) %atomic, i64 noundef 1) #4
  store i64 %call, ptr %val, align 8
  store ptr %val, ptr %val.addr.i, align 8
  %0 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %0) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile xor ptr %2, i64 %4 monotonic, align 8
  %6 = xor i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_acquire_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile xor ptr %2, i64 %4 acquire, align 8
  %6 = xor i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_release_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile xor ptr %2, i64 %4 release, align 8
  %6 = xor i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile xor ptr %2, i64 %4 acq_rel, align 8
  %6 = xor i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile xor ptr %2, i64 %4 seq_cst, align 8
  %6 = xor i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %fromType.addr.i5 = alloca ptr, align 8
  %fromType.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  %retVal = alloca i64, align 8
  %retIntegral = alloca i64, align 8
  %valIntegral = alloca i64, align 8
  %.atomictmp = alloca i64, align 8
  %atomic-temp = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store ptr %arg.addr, ptr %fromType.addr.i5, align 8
  %0 = load ptr, ptr %fromType.addr.i5, align 8
  %1 = load i64, ptr %0, align 8
  store i64 %1, ptr %valIntegral, align 8
  %call2 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedImE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call2, ptr %ptr.addr.i, align 8
  %2 = load ptr, ptr %ptr.addr.i, align 8
  %3 = load i64, ptr %valIntegral, align 8
  store i64 %3, ptr %.atomictmp, align 8
  %4 = load i64, ptr %.atomictmp, align 8
  %5 = atomicrmw volatile xor ptr %2, i64 %4 seq_cst, align 8
  %6 = xor i64 %5, %4
  store i64 %6, ptr %atomic-temp, align 8
  %7 = load i64, ptr %atomic-temp, align 8
  store i64 %7, ptr %retIntegral, align 8
  store ptr %retIntegral, ptr %fromType.addr.i, align 8
  %8 = load ptr, ptr %fromType.addr.i, align 8
  %9 = load i64, ptr %8, align 8
  store i64 %9, ptr %retVal, align 8
  %10 = load i64, ptr %retVal, align 8
  ret i64 %10
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128XorFetchRelaxedv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128XorFetchAcquirev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL28TestAtomic128XorFetchReleasev() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128XorFetchAcqRelv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL27TestAtomic128XorFetchSeqCstv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define internal void @_ZL21TestAtomic128XorFetchv() #0 {
entry:
  %val.addr.i = alloca ptr, align 8
  %atomic = alloca %"struct.eastl::atomic.16", align 16
  %val = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce1 = alloca i128, align 16
  call void @_ZN5eastl6atomicIovEC2Ev(ptr noundef nonnull align 16 dereferenceable(16) %atomic) #4
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEo(ptr noundef nonnull align 16 dereferenceable(16) %atomic, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce1, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce1, align 16
  store i128 %8, ptr %val, align 16
  store ptr %val, ptr %val.addr.i, align 8
  %9 = load ptr, ptr %val.addr.i, align 8
  call void asm sideeffect "", "r,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %9) #4, !srcloc !5
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_relaxed_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %xor = xor i128 %3, %4
  store i128 %xor, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !168
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !169

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %xor17 = xor i128 %18, %19
  store i128 %xor17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_acquire_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %xor = xor i128 %3, %4
  store i128 %xor, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !170
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !171

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %xor17 = xor i128 %18, %19
  store i128 %xor17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_release_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %xor = xor i128 %3, %4
  store i128 %xor, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !172
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !173

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %xor17 = xor i128 %18, %19
  store i128 %xor17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_acq_rel_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %xor = xor i128 %3, %4
  store i128 %xor, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !174
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !175

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %xor17 = xor i128 %18, %19
  store i128 %xor17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %xor = xor i128 %3, %4
  store i128 %xor, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !176
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !177

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %xor17 = xor i128 %18, %19
  store i128 %xor17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %ptr.addr.i23 = alloca ptr, align 8
  %ptr.addr.i22 = alloca ptr, align 8
  %ptr.addr.i21 = alloca ptr, align 8
  %ptr.addr.i20 = alloca ptr, align 8
  %ptr.addr.i19 = alloca ptr, align 8
  %ptr.addr.i18 = alloca ptr, align 8
  %ptr.addr.i = alloca ptr, align 8
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %retVal = alloca i128, align 16
  %cmpxchgRet = alloca i8, align 1
  %computedDesired = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  %2 = load i128, ptr %call, align 16
  store i128 %2, ptr %retVal, align 16
  br label %do.body

do.body:                                          ; preds = %do.cond, %entry
  %3 = load i128, ptr %retVal, align 16
  %4 = load i128, ptr %arg.addr, align 16
  %xor = xor i128 %3, %4
  store i128 %xor, ptr %computedDesired, align 16
  store ptr %retVal, ptr %ptr.addr.i22, align 8
  %5 = load ptr, ptr %ptr.addr.i22, align 8
  %arrayidx = getelementptr inbounds i64, ptr %5, i64 0
  store ptr %retVal, ptr %ptr.addr.i21, align 8
  %6 = load ptr, ptr %ptr.addr.i21, align 8
  %arrayidx5 = getelementptr inbounds i64, ptr %6, i64 1
  %call6 = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIoE16GetAtomicAddressEv(ptr noundef nonnull align 16 dereferenceable(16) %this2) #4
  store ptr %call6, ptr %ptr.addr.i23, align 8
  %7 = load ptr, ptr %ptr.addr.i23, align 8
  store ptr %computedDesired, ptr %ptr.addr.i20, align 8
  %8 = load ptr, ptr %ptr.addr.i20, align 8
  %arrayidx9 = getelementptr inbounds i64, ptr %8, i64 0
  %9 = load i64, ptr %arrayidx9, align 8
  store ptr %computedDesired, ptr %ptr.addr.i19, align 8
  %10 = load ptr, ptr %ptr.addr.i19, align 8
  %arrayidx11 = getelementptr inbounds i64, ptr %10, i64 1
  %11 = load i64, ptr %arrayidx11, align 8
  store ptr %retVal, ptr %ptr.addr.i18, align 8
  %12 = load ptr, ptr %ptr.addr.i18, align 8
  %arrayidx13 = getelementptr inbounds i64, ptr %12, i64 0
  %13 = load i64, ptr %arrayidx13, align 8
  store ptr %retVal, ptr %ptr.addr.i, align 8
  %14 = load ptr, ptr %ptr.addr.i, align 8
  %arrayidx15 = getelementptr inbounds i64, ptr %14, i64 1
  %15 = load i64, ptr %arrayidx15, align 8
  %16 = call { i64, i64 } asm sideeffect "lock; cmpxchg16b $2\0Asete $3", "={ax},={dx},=*m,=*rm,{bx},{cx},{ax},{dx},*m,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(ptr elementtype(i128) %7, ptr elementtype(i8) %cmpxchgRet, i64 %9, i64 %11, i64 %13, i64 %15, ptr elementtype(i128) %7) #4, !srcloc !178
  %asmresult = extractvalue { i64, i64 } %16, 0
  %asmresult16 = extractvalue { i64, i64 } %16, 1
  store i64 %asmresult, ptr %arrayidx, align 8
  store i64 %asmresult16, ptr %arrayidx5, align 8
  br label %do.cond

do.cond:                                          ; preds = %do.body
  %17 = load i8, ptr %cmpxchgRet, align 1
  %tobool = trunc i8 %17 to i1
  %lnot = xor i1 %tobool, true
  br i1 %lnot, label %do.body, label %do.end, !llvm.loop !179

do.end:                                           ; preds = %do.cond
  %18 = load i128, ptr %retVal, align 16
  %19 = load i128, ptr %arg.addr, align 16
  %xor17 = xor i128 %18, %19
  store i128 %xor17, ptr %retVal, align 16
  %20 = load i128, ptr %retVal, align 16
  store i128 %20, ptr %retval, align 16
  %21 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %21
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEppEi(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %0) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %0, ptr %.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_addEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef 1) #4
  ret i32 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEppEi(ptr noundef nonnull align 8 dereferenceable(8) %this, i32 noundef %0) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %0, ptr %.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_addEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this1, i64 noundef 1) #4
  ret i64 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEppEi(ptr noundef nonnull align 16 dereferenceable(16) %this, i32 noundef %0) #0 comdat align 2 {
entry:
  %retval = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %.addr = alloca i32, align 4
  %coerce = alloca i128, align 16
  %coerce2 = alloca i128, align 16
  store ptr %this, ptr %this.addr, align 8
  store i32 %0, ptr %.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store i128 1, ptr %coerce, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %2 = load i64, ptr %1, align 16
  %3 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %4 = load i64, ptr %3, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_addEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this1, i64 noundef %2, i64 noundef %4) #4
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce2, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %call, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce2, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %call, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce2, align 16
  store i128 %9, ptr %retval, align 16
  %10 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEppEv(ptr noundef nonnull align 4 dereferenceable(4) %this) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef 1) #4
  ret i32 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEppEv(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this1, i64 noundef 1) #4
  ret i64 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEppEv(ptr noundef nonnull align 16 dereferenceable(16) %this) #0 comdat align 2 {
entry:
  %retval = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %coerce = alloca i128, align 16
  %coerce2 = alloca i128, align 16
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this1, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce2, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce2, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce2, align 16
  store i128 %8, ptr %retval, align 16
  %9 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEmmEi(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %0) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %0, ptr %.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9fetch_subEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef 1) #4
  ret i32 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEmmEi(ptr noundef nonnull align 8 dereferenceable(8) %this, i32 noundef %0) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %0, ptr %.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9fetch_subEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this1, i64 noundef 1) #4
  ret i64 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEmmEi(ptr noundef nonnull align 16 dereferenceable(16) %this, i32 noundef %0) #0 comdat align 2 {
entry:
  %retval = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %.addr = alloca i32, align 4
  %coerce = alloca i128, align 16
  %coerce2 = alloca i128, align 16
  store ptr %this, ptr %this.addr, align 8
  store i32 %0, ptr %.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  store i128 1, ptr %coerce, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %2 = load i64, ptr %1, align 16
  %3 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %4 = load i64, ptr %3, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9fetch_subEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this1, i64 noundef %2, i64 noundef %4) #4
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce2, i32 0, i32 0
  %6 = extractvalue { i64, i64 } %call, 0
  store i64 %6, ptr %5, align 16
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce2, i32 0, i32 1
  %8 = extractvalue { i64, i64 } %call, 1
  store i64 %8, ptr %7, align 8
  %9 = load i128, ptr %coerce2, align 16
  store i128 %9, ptr %retval, align 16
  %10 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %10
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEmmEv(ptr noundef nonnull align 4 dereferenceable(4) %this) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef 1) #4
  ret i32 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEmmEv(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this1, i64 noundef 1) #4
  ret i64 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEmmEv(ptr noundef nonnull align 16 dereferenceable(16) %this) #0 comdat align 2 {
entry:
  %retval = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %coerce = alloca i128, align 16
  %coerce2 = alloca i128, align 16
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  store i128 1, ptr %coerce, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %1 = load i64, ptr %0, align 16
  %2 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %3 = load i64, ptr %2, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this1, i64 noundef %1, i64 noundef %3) #4
  %4 = getelementptr inbounds { i64, i64 }, ptr %coerce2, i32 0, i32 0
  %5 = extractvalue { i64, i64 } %call, 0
  store i64 %5, ptr %4, align 16
  %6 = getelementptr inbounds { i64, i64 }, ptr %coerce2, i32 0, i32 1
  %7 = extractvalue { i64, i64 } %call, 1
  store i64 %7, ptr %6, align 8
  %8 = load i128, ptr %coerce2, align 16
  store i128 %8, ptr %retval, align 16
  %9 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %9
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEpLEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i32, ptr %arg.addr, align 4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9add_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef %0) #4
  ret i32 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEpLEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i64, ptr %arg.addr, align 8
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9add_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this1, i64 noundef %0) #4
  ret i64 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEpLEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce3 = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %2 = load i128, ptr %arg.addr, align 16
  store i128 %2, ptr %coerce, align 16
  %3 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %4 = load i64, ptr %3, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %6 = load i64, ptr %5, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9add_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this2, i64 noundef %4, i64 noundef %6) #4
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce3, i32 0, i32 0
  %8 = extractvalue { i64, i64 } %call, 0
  store i64 %8, ptr %7, align 16
  %9 = getelementptr inbounds { i64, i64 }, ptr %coerce3, i32 0, i32 1
  %10 = extractvalue { i64, i64 } %call, 1
  store i64 %10, ptr %9, align 8
  %11 = load i128, ptr %coerce3, align 16
  store i128 %11, ptr %retval, align 16
  %12 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %12
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEmIEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i32, ptr %arg.addr, align 4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9sub_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef %0) #4
  ret i32 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEmIEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i64, ptr %arg.addr, align 8
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9sub_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this1, i64 noundef %0) #4
  ret i64 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEmIEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce3 = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %2 = load i128, ptr %arg.addr, align 16
  store i128 %2, ptr %coerce, align 16
  %3 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %4 = load i64, ptr %3, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %6 = load i64, ptr %5, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9sub_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this2, i64 noundef %4, i64 noundef %6) #4
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce3, i32 0, i32 0
  %8 = extractvalue { i64, i64 } %call, 0
  store i64 %8, ptr %7, align 16
  %9 = getelementptr inbounds { i64, i64 }, ptr %coerce3, i32 0, i32 1
  %10 = extractvalue { i64, i64 } %call, 1
  store i64 %10, ptr %9, align 8
  %11 = load i128, ptr %coerce3, align 16
  store i128 %11, ptr %retval, align 16
  %12 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %12
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEaNEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i32, ptr %arg.addr, align 4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9and_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef %0) #4
  ret i32 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEaNEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i64, ptr %arg.addr, align 8
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9and_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this1, i64 noundef %0) #4
  ret i64 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEaNEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce3 = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %2 = load i128, ptr %arg.addr, align 16
  store i128 %2, ptr %coerce, align 16
  %3 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %4 = load i64, ptr %3, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %6 = load i64, ptr %5, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9and_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this2, i64 noundef %4, i64 noundef %6) #4
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce3, i32 0, i32 0
  %8 = extractvalue { i64, i64 } %call, 0
  store i64 %8, ptr %7, align 16
  %9 = getelementptr inbounds { i64, i64 }, ptr %coerce3, i32 0, i32 1
  %10 = extractvalue { i64, i64 } %call, 1
  store i64 %10, ptr %9, align 8
  %11 = load i128, ptr %coerce3, align 16
  store i128 %11, ptr %retval, align 16
  %12 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %12
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEoREj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i32, ptr %arg.addr, align 4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE8or_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef %0) #4
  ret i32 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEoREm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i64, ptr %arg.addr, align 8
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE8or_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this1, i64 noundef %0) #4
  ret i64 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEoREo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce3 = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %2 = load i128, ptr %arg.addr, align 16
  store i128 %2, ptr %coerce, align 16
  %3 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %4 = load i64, ptr %3, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %6 = load i64, ptr %5, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE8or_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this2, i64 noundef %4, i64 noundef %6) #4
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce3, i32 0, i32 0
  %8 = extractvalue { i64, i64 } %call, 0
  store i64 %8, ptr %7, align 16
  %9 = getelementptr inbounds { i64, i64 }, ptr %coerce3, i32 0, i32 1
  %10 = extractvalue { i64, i64 } %call, 1
  store i64 %10, ptr %9, align 8
  %11 = load i128, ptr %coerce3, align 16
  store i128 %11, ptr %retval, align 16
  %12 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %12
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EEeOEj(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %arg) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %arg, ptr %arg.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i32, ptr %arg.addr, align 4
  %call = call noundef i32 @_ZN5eastl8internal21atomic_integral_widthIjLj4EE9xor_fetchEjNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef %0) #4
  ret i32 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EEeOEm(ptr noundef nonnull align 8 dereferenceable(8) %this, i64 noundef %arg) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i64, align 8
  store ptr %this, ptr %this.addr, align 8
  store i64 %arg, ptr %arg.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i64, ptr %arg.addr, align 8
  %call = call noundef i64 @_ZN5eastl8internal21atomic_integral_widthImLj8EE9xor_fetchEmNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 8 dereferenceable(8) %this1, i64 noundef %0) #4
  ret i64 %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EEeOEo(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 noundef %arg.coerce0, i64 noundef %arg.coerce1) #0 comdat align 2 {
entry:
  %retval = alloca i128, align 16
  %arg = alloca i128, align 16
  %this.addr = alloca ptr, align 8
  %arg.addr = alloca i128, align 16
  %coerce = alloca i128, align 16
  %coerce3 = alloca i128, align 16
  %0 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 0
  store i64 %arg.coerce0, ptr %0, align 16
  %1 = getelementptr inbounds { i64, i64 }, ptr %arg, i32 0, i32 1
  store i64 %arg.coerce1, ptr %1, align 8
  %arg1 = load i128, ptr %arg, align 16
  store ptr %this, ptr %this.addr, align 8
  store i128 %arg1, ptr %arg.addr, align 16
  %this2 = load ptr, ptr %this.addr, align 8
  %2 = load i128, ptr %arg.addr, align 16
  store i128 %2, ptr %coerce, align 16
  %3 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 0
  %4 = load i64, ptr %3, align 16
  %5 = getelementptr inbounds { i64, i64 }, ptr %coerce, i32 0, i32 1
  %6 = load i64, ptr %5, align 8
  %call = call noundef { i64, i64 } @_ZN5eastl8internal21atomic_integral_widthIoLj16EE9xor_fetchEoNS0_22memory_order_seq_cst_sE(ptr noundef nonnull align 16 dereferenceable(16) %this2, i64 noundef %4, i64 noundef %6) #4
  %7 = getelementptr inbounds { i64, i64 }, ptr %coerce3, i32 0, i32 0
  %8 = extractvalue { i64, i64 } %call, 0
  store i64 %8, ptr %7, align 16
  %9 = getelementptr inbounds { i64, i64 }, ptr %coerce3, i32 0, i32 1
  %10 = extractvalue { i64, i64 } %call, 1
  store i64 %10, ptr %9, align 8
  %11 = load i128, ptr %coerce3, align 16
  store i128 %11, ptr %retval, align 16
  %12 = load { i64, i64 }, ptr %retval, align 16
  ret { i64, i64 } %12
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl6atomicIPvvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal20atomic_pointer_widthIPvLj8EEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl8internal20atomic_pointer_widthIPvLj8EE4loadENS0_27memory_order_read_depends_sE(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %retPointer = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIPvE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call, ptr %ptr.addr.i, align 8
  %0 = load ptr, ptr %ptr.addr.i, align 8
  %1 = load volatile ptr, ptr %0, align 8
  store ptr %1, ptr %retPointer, align 8
  %2 = load ptr, ptr %retPointer, align 8
  ret ptr %2
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal20atomic_pointer_widthIPvLj8EEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal19atomic_pointer_baseIPvLj8EEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal19atomic_pointer_baseIPvLj8EEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal17atomic_base_widthIPvLj8EEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthIPvLj8EEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @_ZN5eastl8internal19atomic_size_alignedIPvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal19atomic_size_alignedIPvEC2Ev(ptr noundef nonnull align 8 dereferenceable(8) %this) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned.25", ptr %this1, i32 0, i32 0
  store ptr null, ptr %mAtomic, align 8
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIPvE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned.25", ptr %this1, i32 0, i32 0
  %call = call noundef ptr @_ZN5eastl9addressofIPvEEPT_RS2_(ptr noundef nonnull align 8 dereferenceable(8) %mAtomic) #4
  ret ptr %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofIPvEEPT_RS2_(ptr noundef nonnull align 8 dereferenceable(8) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl8internal20atomic_pointer_widthIPP20ReadDependsIntrusiveLj8EE4loadENS0_27memory_order_read_depends_sE(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %ptr.addr.i = alloca ptr, align 8
  %this.addr = alloca ptr, align 8
  %retPointer = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %call = call noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIPP20ReadDependsIntrusiveE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this1) #4
  store ptr %call, ptr %ptr.addr.i, align 8
  %0 = load ptr, ptr %ptr.addr.i, align 8
  %1 = load volatile ptr, ptr %0, align 8
  store ptr %1, ptr %retPointer, align 8
  %2 = load ptr, ptr %retPointer, align 8
  ret ptr %2
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIPP20ReadDependsIntrusiveE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned.4", ptr %this1, i32 0, i32 0
  %call = call noundef ptr @_ZN5eastl9addressofIPP20ReadDependsIntrusiveEEPT_RS4_(ptr noundef nonnull align 8 dereferenceable(8) %mAtomic) #4
  ret ptr %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofIPP20ReadDependsIntrusiveEEPT_RS4_(ptr noundef nonnull align 8 dereferenceable(8) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl6atomicIjvEC2Ej(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i32, ptr %desired.addr, align 4
  call void @_ZN5eastl8internal21atomic_integral_widthIjLj4EEC2Ej(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef %0) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal21atomic_integral_widthIjLj4EEC2Ej(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i32, ptr %desired.addr, align 4
  call void @_ZN5eastl8internal20atomic_integral_baseIjLj4EEC2Ej(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef %0) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal20atomic_integral_baseIjLj4EEC2Ej(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i32, ptr %desired.addr, align 4
  call void @_ZN5eastl8internal17atomic_base_widthIjLj4EEC2Ej(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef %0) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthIjLj4EEC2Ej(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %0 = load i32, ptr %desired.addr, align 4
  call void @_ZN5eastl8internal19atomic_size_alignedIjEC2Ej(ptr noundef nonnull align 4 dereferenceable(4) %this1, i32 noundef %0) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal19atomic_size_alignedIjEC2Ej(ptr noundef nonnull align 4 dereferenceable(4) %this, i32 noundef %desired) unnamed_addr #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  %desired.addr = alloca i32, align 4
  store ptr %this, ptr %this.addr, align 8
  store i32 %desired, ptr %desired.addr, align 4
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned.7", ptr %this1, i32 0, i32 0
  %0 = load i32, ptr %desired.addr, align 4
  store i32 %0, ptr %mAtomic, align 4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl6atomicI11UserType128vEC2ES1_(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 %desired.coerce0, i64 %desired.coerce1) unnamed_addr #0 comdat align 2 {
entry:
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %agg.tmp = alloca %struct.UserType128, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %agg.tmp, ptr align 4 %desired, i64 16, i1 false)
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %3 = load i64, ptr %2, align 4
  %4 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %5 = load i64, ptr %4, align 4
  call void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EEC2ES2_(ptr noundef nonnull align 16 dereferenceable(16) %this1, i64 %3, i64 %5) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal17atomic_base_widthI11UserType128Lj16EEC2ES2_(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 %desired.coerce0, i64 %desired.coerce1) unnamed_addr #0 comdat align 2 {
entry:
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %agg.tmp = alloca %struct.UserType128, align 4
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  call void @llvm.memcpy.p0.p0.i64(ptr align 4 %agg.tmp, ptr align 4 %desired, i64 16, i1 false)
  %2 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 0
  %3 = load i64, ptr %2, align 4
  %4 = getelementptr inbounds { i64, i64 }, ptr %agg.tmp, i32 0, i32 1
  %5 = load i64, ptr %4, align 4
  call void @_ZN5eastl8internal19atomic_size_alignedI11UserType128EC2ES2_(ptr noundef nonnull align 16 dereferenceable(16) %this1, i64 %3, i64 %5) #4
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local void @_ZN5eastl8internal19atomic_size_alignedI11UserType128EC2ES2_(ptr noundef nonnull align 16 dereferenceable(16) %this, i64 %desired.coerce0, i64 %desired.coerce1) unnamed_addr #0 comdat align 2 {
entry:
  %desired = alloca %struct.UserType128, align 4
  %this.addr = alloca ptr, align 8
  %0 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 0
  store i64 %desired.coerce0, ptr %0, align 4
  %1 = getelementptr inbounds { i64, i64 }, ptr %desired, i32 0, i32 1
  store i64 %desired.coerce1, ptr %1, align 4
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned.15", ptr %this1, i32 0, i32 0
  call void @llvm.memcpy.p0.p0.i64(ptr align 16 %mAtomic, ptr align 4 %desired, i64 16, i1 false)
  ret void
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZNK5eastl8internal19atomic_size_alignedIP17ReadDependsStructE16GetAtomicAddressEv(ptr noundef nonnull align 8 dereferenceable(8) %this) #0 comdat align 2 {
entry:
  %this.addr = alloca ptr, align 8
  store ptr %this, ptr %this.addr, align 8
  %this1 = load ptr, ptr %this.addr, align 8
  %mAtomic = getelementptr inbounds %"struct.eastl::internal::atomic_size_aligned", ptr %this1, i32 0, i32 0
  %call = call noundef ptr @_ZN5eastl9addressofIP17ReadDependsStructEEPT_RS3_(ptr noundef nonnull align 8 dereferenceable(8) %mAtomic) #4
  ret ptr %call
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofIP17ReadDependsStructEEPT_RS3_(ptr noundef nonnull align 8 dereferenceable(8) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofINS_15aligned_storageILm8ELm8EE4typeEEEPT_RS4_(ptr noundef nonnull align 8 dereferenceable(8) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofIKP17ReadDependsStructEEPT_RS4_(ptr noundef nonnull align 8 dereferenceable(8) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

; Function Attrs: mustprogress nounwind uwtable
define linkonce_odr dso_local noundef ptr @_ZN5eastl9addressofIKPP20ReadDependsIntrusiveEEPT_RS5_(ptr noundef nonnull align 8 dereferenceable(8) %value) #0 comdat {
entry:
  %value.addr = alloca ptr, align 8
  store ptr %value, ptr %value.addr, align 8
  %0 = load ptr, ptr %value.addr, align 8
  ret ptr %0
}

attributes #0 = { mustprogress nounwind uwtable "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #1 = { mustprogress uwtable "frame-pointer"="all" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cmov,+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "tune-cpu"="generic" }
attributes #2 = { nocallback nofree nounwind willreturn memory(argmem: readwrite) }
attributes #3 = { nocallback nofree nounwind willreturn memory(argmem: write) }
attributes #4 = { nounwind }

!llvm.module.flags = !{!0, !1, !2, !3, !4}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 8, !"PIC Level", i32 2}
!2 = !{i32 7, !"PIE Level", i32 2}
!3 = !{i32 7, !"uwtable", i32 2}
!4 = !{i32 7, !"frame-pointer", i32 2}
!5 = !{i64 2156633145}
!6 = !{i64 2156612098}
!7 = !{i64 2154046168, i64 2154046237}
!8 = distinct !{!8, !9}
!9 = !{!"llvm.loop.mustprogress"}
!10 = !{i64 2154060091, i64 2154060160}
!11 = distinct !{!11, !9}
!12 = !{i64 2154074014, i64 2154074083}
!13 = distinct !{!13, !9}
!14 = !{i64 2154028184, i64 2154028253}
!15 = distinct !{!15, !9}
!16 = !{i64 2154085612}
!17 = !{i64 2154091392}
!18 = !{i64 2154101233}
!19 = !{i64 2154079832}
!20 = !{i64 2154123684, i64 2154123753}
!21 = distinct !{!21, !9}
!22 = !{i64 2154134941, i64 2154135010}
!23 = distinct !{!23, !9}
!24 = !{i64 2154146198, i64 2154146267}
!25 = distinct !{!25, !9}
!26 = !{i64 2154161516, i64 2154161585}
!27 = distinct !{!27, !9}
!28 = !{i64 2154112427, i64 2154112496}
!29 = distinct !{!29, !9}
!30 = !{i64 2154261821, i64 2154261890}
!31 = !{i64 2154277266, i64 2154277335}
!32 = !{i64 2154288650, i64 2154288719}
!33 = !{i64 2154300034, i64 2154300103}
!34 = !{i64 2154311418, i64 2154311487}
!35 = !{i64 2154326863, i64 2154326932}
!36 = !{i64 2154338247, i64 2154338316}
!37 = !{i64 2154349631, i64 2154349700}
!38 = !{i64 2154361015, i64 2154361084}
!39 = !{i64 2154200504, i64 2154200573}
!40 = !{i64 2154216033, i64 2154216102}
!41 = !{i64 2154227501, i64 2154227570}
!42 = !{i64 2154238969, i64 2154239038}
!43 = !{i64 2154250437, i64 2154250506}
!44 = !{i64 2154189036, i64 2154189105}
!45 = !{i64 2154429650, i64 2154429719}
!46 = !{i64 2154442117, i64 2154442186}
!47 = !{i64 2154450523, i64 2154450592}
!48 = !{i64 2154458929, i64 2154458998}
!49 = !{i64 2154467335, i64 2154467404}
!50 = !{i64 2154475741, i64 2154475810}
!51 = !{i64 2154484147, i64 2154484216}
!52 = !{i64 2154492553, i64 2154492622}
!53 = !{i64 2154505020, i64 2154505089}
!54 = !{i64 2154387260, i64 2154387329}
!55 = !{i64 2154395756, i64 2154395825}
!56 = !{i64 2154404252, i64 2154404321}
!57 = !{i64 2154412748, i64 2154412817}
!58 = !{i64 2154421244, i64 2154421313}
!59 = !{i64 2154374703, i64 2154374772}
!60 = !{i64 2155772610, i64 2155772679}
!61 = distinct !{!61, !9}
!62 = !{i64 2155782270, i64 2155782339}
!63 = distinct !{!63, !9}
!64 = !{i64 2155791930, i64 2155791999}
!65 = distinct !{!65, !9}
!66 = !{i64 2155801590, i64 2155801659}
!67 = distinct !{!67, !9}
!68 = !{i64 2155811250, i64 2155811319}
!69 = distinct !{!69, !9}
!70 = !{i64 2155758889, i64 2155758958}
!71 = distinct !{!71, !9}
!72 = !{i64 2155835925, i64 2155835994}
!73 = distinct !{!73, !9}
!74 = !{i64 2155845650, i64 2155845719}
!75 = distinct !{!75, !9}
!76 = !{i64 2155855375, i64 2155855444}
!77 = distinct !{!77, !9}
!78 = !{i64 2155865100, i64 2155865169}
!79 = distinct !{!79, !9}
!80 = !{i64 2155874825, i64 2155874894}
!81 = distinct !{!81, !9}
!82 = !{i64 2155826200, i64 2155826269}
!83 = distinct !{!83, !9}
!84 = !{i64 2155899476, i64 2155899545}
!85 = distinct !{!85, !9}
!86 = !{i64 2155909136, i64 2155909205}
!87 = distinct !{!87, !9}
!88 = !{i64 2155918796, i64 2155918865}
!89 = distinct !{!89, !9}
!90 = !{i64 2155928456, i64 2155928525}
!91 = distinct !{!91, !9}
!92 = !{i64 2155942177, i64 2155942246}
!93 = distinct !{!93, !9}
!94 = !{i64 2155889816, i64 2155889885}
!95 = distinct !{!95, !9}
!96 = !{i64 2155962791, i64 2155962860}
!97 = distinct !{!97, !9}
!98 = !{i64 2155972516, i64 2155972585}
!99 = distinct !{!99, !9}
!100 = !{i64 2155982241, i64 2155982310}
!101 = distinct !{!101, !9}
!102 = !{i64 2155991966, i64 2155992035}
!103 = distinct !{!103, !9}
!104 = !{i64 2156005752, i64 2156005821}
!105 = distinct !{!105, !9}
!106 = !{i64 2155953066, i64 2155953135}
!107 = distinct !{!107, !9}
!108 = !{i64 2156026342, i64 2156026411}
!109 = distinct !{!109, !9}
!110 = !{i64 2156036002, i64 2156036071}
!111 = distinct !{!111, !9}
!112 = !{i64 2156045662, i64 2156045731}
!113 = distinct !{!113, !9}
!114 = !{i64 2156059383, i64 2156059452}
!115 = distinct !{!115, !9}
!116 = !{i64 2156069043, i64 2156069112}
!117 = distinct !{!117, !9}
!118 = !{i64 2156016682, i64 2156016751}
!119 = distinct !{!119, !9}
!120 = !{i64 2156089657, i64 2156089726}
!121 = distinct !{!121, !9}
!122 = !{i64 2156099382, i64 2156099451}
!123 = distinct !{!123, !9}
!124 = !{i64 2156109107, i64 2156109176}
!125 = distinct !{!125, !9}
!126 = !{i64 2156122893, i64 2156122962}
!127 = distinct !{!127, !9}
!128 = !{i64 2156132618, i64 2156132687}
!129 = distinct !{!129, !9}
!130 = !{i64 2156079932, i64 2156080001}
!131 = distinct !{!131, !9}
!132 = !{i64 2156153103, i64 2156153172}
!133 = distinct !{!133, !9}
!134 = !{i64 2156162717, i64 2156162786}
!135 = distinct !{!135, !9}
!136 = !{i64 2156176392, i64 2156176461}
!137 = distinct !{!137, !9}
!138 = !{i64 2156186006, i64 2156186075}
!139 = distinct !{!139, !9}
!140 = !{i64 2156195620, i64 2156195689}
!141 = distinct !{!141, !9}
!142 = !{i64 2156143489, i64 2156143558}
!143 = distinct !{!143, !9}
!144 = !{i64 2156216125, i64 2156216194}
!145 = distinct !{!145, !9}
!146 = !{i64 2156225802, i64 2156225871}
!147 = distinct !{!147, !9}
!148 = !{i64 2156239540, i64 2156239609}
!149 = distinct !{!149, !9}
!150 = !{i64 2156249217, i64 2156249286}
!151 = distinct !{!151, !9}
!152 = !{i64 2156258894, i64 2156258963}
!153 = distinct !{!153, !9}
!154 = !{i64 2156206448, i64 2156206517}
!155 = distinct !{!155, !9}
!156 = !{i64 2156279484, i64 2156279553}
!157 = distinct !{!157, !9}
!158 = !{i64 2156293205, i64 2156293274}
!159 = distinct !{!159, !9}
!160 = !{i64 2156302865, i64 2156302934}
!161 = distinct !{!161, !9}
!162 = !{i64 2156312525, i64 2156312594}
!163 = distinct !{!163, !9}
!164 = !{i64 2156322185, i64 2156322254}
!165 = distinct !{!165, !9}
!166 = !{i64 2156269824, i64 2156269893}
!167 = distinct !{!167, !9}
!168 = !{i64 2156346860, i64 2156346929}
!169 = distinct !{!169, !9}
!170 = !{i64 2156356585, i64 2156356654}
!171 = distinct !{!171, !9}
!172 = !{i64 2156366310, i64 2156366379}
!173 = distinct !{!173, !9}
!174 = !{i64 2156376035, i64 2156376104}
!175 = distinct !{!175, !9}
!176 = !{i64 2156385760, i64 2156385829}
!177 = distinct !{!177, !9}
!178 = !{i64 2156333074, i64 2156333143}
!179 = distinct !{!179, !9}
